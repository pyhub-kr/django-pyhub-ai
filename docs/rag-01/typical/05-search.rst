5ë‹¨ê³„. ì§€ì‹ ê²€ìƒ‰ (Search) ë° LLM ìš”ì²­/ì‘ë‹µ
===========================================

  ì €ì¥ëœ ì§€ì‹ì„ ê²€ìƒ‰í•˜ì—¬ LLMì—ê²Œ ì „ë‹¬í•˜ê³  ìµœì¢… ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ê³¼ì •

ë³¸ í˜ì´ì§€ëŠ” 59:33 ì§€ì ë¶€í„° 1:13:10 ì§€ì ê¹Œì§€ ë³´ì‹œë©´ ë©ë‹ˆë‹¤.

.. raw:: html

  <div class="video-container">
    <iframe
        src="https://www.youtube.com/embed/9ayknWI-VcI?start=3573"
        frameborder="0"
        allowfullscreen>
    </iframe>
  </div>

----

í•„ìš”ì„±
----------

RAG ì‹œìŠ¤í…œì˜ ëª©ì ì€ LLMì´ ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ë‹µë³€í•˜ë„ë¡ ìœ ë„í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

.. figure:: ./assets/typical-retrieval-and-generation.png
   :alt: (RAG) Retrieval and Generation

   ì¶œì²˜ : `ë­ì²´ì¸ ê³µì‹ íŠœí† ë¦¬ì–¼: RAG ì• í”Œë¦¬ì¼€ì´ì…˜ êµ¬ì¶•í•˜ê¸° <https://python.langchain.com/docs/tutorials/rag/>`_

#. Question : ìœ ì €ë¡œë¶€í„° ì§ˆë¬¸ ë°›ê¸°
#. Retrieve : ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ê°€ ì €ì¥ëœ Vector Storeì—ì„œ ì§ˆë¬¸ê³¼ ìœ ì‚¬ë„ê°€ ë†’ì€ ë¬¸ì„œë“¤ì„ kê°œ ì°¾ê¸° 
#. Prompt : ì§ˆë¬¸ê³¼ ì°¾ì€ ë¬¸ì„œë“¤ì„ í”„ë¡¬í”„íŠ¸ì— í¬í•¨ì‹œì¼œ LLMì—ê²Œ ìš”ì²­

ê° ë‹¨ê³„ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ìˆ˜í–‰í•˜ê³  ìœ ì €ì—ê²Œ ë‹µë³€ì„ ì „ë‹¬í•©ë‹ˆë‹¤.
ì˜ëª»ëœ ë¬¸ì„œê°€ ê²€ìƒ‰ë˜ë”ë¼ë„ ì´ë¥¼ ê²€ì¦í•˜ëŠ” ë‹¨ê³„ëŠ” ì—†ìŠµë‹ˆë‹¤.

.. tip::
   ì§ˆë¬¸ê³¼ ìœ ì‚¬ ë¬¸ì„œì˜ í’ˆì§ˆì„ í‰ê°€í•´ì„œ, ì¬ì§ˆë¬¸ í˜¹ì€ ë¬¸ì„œ ì¬ê²€ìƒ‰ì„ ìˆ˜í–‰í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.

   RAG ê²€ìƒ‰ ê³¼ì •ì´ ë¬´ì¡°ê±´ Question â†’ Retrieve â†’ Prompt ìˆœì„œë¡œ ì§„í–‰í•´ì•¼ë§Œ í•˜ëŠ” ê²ƒì€ ì•„ë‹™ë‹ˆë‹¤.
   ë‹¤ì–‘í•œ í”„ë¡œì„¸ìŠ¤ê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. **ì½”ë“œë¡œ êµ¬í˜„í•˜ê¸° ë‚˜ë¦„**\ì…ë‹ˆë‹¤.

   ì§ˆë¬¸ê³¼ ìœ ì‚¬ ë¬¸ì„œì˜ í’ˆì§ˆì„ í‰ê°€í•´ì„œ, ì¬ì§ˆë¬¸ í˜¹ì€ ë¬¸ì„œ ì¬ê²€ìƒ‰ì„ ìˆ˜í–‰í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
   ì´ëŸ¬í•œ Flowë¥¼ íŒŒì´ì¬ ì½”ë“œë¡œ ì§ì ‘ êµ¬í˜„í•  ìˆ˜ë„ ìˆê² êµ¬ìš”.
   ``LangGraph`` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í†µí•´ Flow êµ¬ì„±ì„ ì¢€ ë” ì§ê´€ì ìœ¼ë¡œ í•˜ì‹¤ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
   ``LangGraph``\ê°€ í•„ìˆ˜ì¸ ê²ƒì€ ì•„ë‹™ë‹ˆë‹¤. í•˜ë‚˜ì˜ ì„ íƒì§€ì¼ ë¿ì…ë‹ˆë‹¤.


íŒŒì´ì¬ êµ¬í˜„
----------------

``VectorStore`` í´ë˜ìŠ¤ì— ``search`` ë©”ì„œë“œ êµ¬í˜„
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

ë¨¼ì € ì§ˆë¬¸ê³¼ ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ ì°¾ì•„ì£¼ëŠ” ``search`` ë©”ì„œë“œë¥¼ ``VectoreStore`` í´ë˜ìŠ¤ì— êµ¬í˜„í•´ë´…ì‹œë‹¤.

1. ì¸ìë¡œ ì§ˆë¬¸ê³¼ ì°¾ê³ ì í•˜ëŠ” ìœ ì‚¬ ë¬¸ì„œ ê°œìˆ˜ë¥¼ ë°›ìŠµë‹ˆë‹¤.

   - ìœ ì‚¬ ë¬¸ì„œ ê°œìˆ˜ëŠ” ë””í´íŠ¸ë¡œ ``4``\ë¥¼ ì§€ì •í–ˆêµ¬ìš”. ë­ì²´ì¸ì—ì„œë„ ë””í´íŠ¸ë¡œ ``4``\ì…ë‹ˆë‹¤.

2. ì§ˆë¬¸ ë¬¸ìì—´ì„ ì„ë² ë”© ë²¡í„° ë°°ì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

3. ì§ˆë¬¸ê³¼ VectorStore ë‚´ì— ì €ì¥ëœ ëª¨ë“  ë¬¸ì„œë“¤ê³¼ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.

4. ìœ ì‚¬ë„ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ``k``\ê°œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

.. code-block:: python
   :linenos:
   :emphasize-lines: 2-3,12-36

   import openai
   import numpy as np
   from sklearn.metrics.pairwise import cosine_similarity

   client = openai.Client()

   class VectorStore(list):
       embedding_model = "text-embedding-3-small"

       # ...

       def search(self, question: str, k: int = 4) -> List[Document]:
           """
           ì§ˆì˜ ë¬¸ìì—´ì„ ë°›ì•„ì„œ, ë²¡í„° ìŠ¤í† ì–´ì—ì„œ ìœ ì‚¬ ë¬¸ì„œë¥¼ ìµœëŒ€ kê°œ ë°˜í™˜
           """

           # ì§ˆë¬¸ ë¬¸ìì—´ì„ ì„ë² ë”© ë²¡í„° ë°°ì—´ë¡œ ë³€í™˜
           response = client.embeddings.create(
               model=self.embedding_model,
               input=question,
           )
           question_embedding = response.data[0].embedding  # 1536 ì°¨ì›, float ë°°ì—´

           # VectorStore ë‚´ì— ì €ì¥ëœ ëª¨ë“  ë²¡í„° ë°ì´í„°ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì¶”ì¶œ
           embedding_list = [row["embedding"] for row in self]

           # ëª¨ë“  ë¬¸ì„œì™€ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
           similarities = cosine_similarity([question_embedding], embedding_list)[0]
           # ìœ ì‚¬ë„ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ k ê°œ ì„ íƒ
           top_indices = np.argsort(similarities)[::-1][:k]

           # ìƒìœ„ k ê°œ ë¬¸ì„œë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜
           return [
               self[idx]["document"].model_copy()
               for idx in top_indices
           ]

1ë‹¨ê³„. Question
~~~~~~~~~~~~~~~~~~~~

RAGë¥¼ ìˆ˜í–‰í•  ì§ˆë¬¸ì„ ë¨¼ì € ì •ì˜í•©ë‹ˆë‹¤.

.. code-block:: python
   :linenos:

   question = "ë¹½ë‹¤ë°© ì¹´í˜ì¸ì´ ë†’ì€ ìŒë£Œì™€ ê°€ê²©ì€?"


2ë‹¨ê³„. Retrieve
~~~~~~~~~~~~~~~~~~~~

``vector_store`` ì—ì„œ ì§ˆë¬¸ê³¼ ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ ì°¾ì•„ì„œ, í”„ë¡¬í”„íŠ¸ì— ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ``ì§€ì‹`` ë¬¸ìì—´ ë³€ìˆ˜ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

.. code-block:: python
   :linenos:

   search_doc_list: List[Document] = vector_store.search(question)
   pprint(search_doc_list)

   print("## ì§€ì‹ ##")
   ì§€ì‹: str = str(search_doc_list)
   print(repr(ì§€ì‹))

ì•„ë˜ì™€ ê°™ì´ ìœ ì‚¬ ë¬¸ì„œë¥¼ ì°¾ì•„, ``ì§€ì‹`` ë¬¸ìì—´ê¹Œì§€ ì˜ ìƒì„±í–ˆìŠµë‹ˆë‹¤.

.. code-block:: text

   [Document(metadata={'source': 'ë¹½ë‹¤ë°©.txt'}, page_content='5. ë¹½ì‚¬ì´ì¦ˆ ì›ì¡°ì»¤í”¼(ICED)\n  - ë¹½ë‹¤ë°©ì˜ BESTë©”ë‰´ë¥¼ ë” í¬ê²Œ ì¦ê²¨ë³´ì„¸ìš” :) [ì£¼ì˜. 564mg ê³ ì¹´í˜ì¸ìœ¼ë¡œ ì¹´í˜ì¸ì— ë¯¼ê°í•œ ì–´ë¦°ì´, ì„ì‚°ë¶€ëŠ” ì„­ì·¨ì— ì£¼ì˜ë°”ëë‹ˆë‹¤]\n  - ê°€ê²©: 4000ì›'),
    Document(metadata={'source': 'ë¹½ë‹¤ë°©.txt'}, page_content='6. ë¹½ì‚¬ì´ì¦ˆ ì›ì¡°ì»¤í”¼ ì œë¡œìŠˆê±°(ICED)\n  - ë¹½ë‹¤ë°©ì˜ BESTë©”ë‰´ë¥¼ ë” í¬ê²Œ, ì œë¡œìŠˆê±°ë¡œ ì¦ê²¨ë³´ì„¸ìš” :) [ì£¼ì˜. 686mg ê³ ì¹´í˜ì¸ìœ¼ë¡œ ì¹´í˜ì¸ì— ë¯¼ê°í•œ ì–´ë¦°ì´, ì„ì‚°ë¶€ëŠ” ì„­ì·¨ì— ì£¼ì˜ë°”ëë‹ˆë‹¤]\n  - ê°€ê²©: 4000ì›'),
    Document(metadata={'source': 'ë¹½ë‹¤ë°©.txt'}, page_content='3. ì‚¬ë¼ë‹¤ë¹µ\n  - ë¹½ë‹¤ë°©ì˜ ëŒ€í‘œë©”ë‰´ :) ì¶”ì–µì˜ ê°ì ì‚¬ë¼ë‹¤ë¹µ\n  - ê°€ê²©: 3900ì›'),
    Document(metadata={'source': 'ë¹½ë‹¤ë°©.txt'}, page_content='2. ë°”ë‹ë¼ë¼ë–¼(ICED)\n  - ë¶€ë“œëŸ¬ìš´ ìš°ìœ ì™€ ë‹¬ì½¤í•˜ê³  ì€ì€í•œ ë°”ë‹ë¼ê°€ ì¡°í™”ë¥¼ ì´ë£¨ëŠ” ìŒë£Œ\n  - ê°€ê²©: 4200ì›')]
   ## ì§€ì‹ ##
   "[Document(metadata={'source': 'ë¹½ë‹¤ë°©.txt'}, page_content='5. ë¹½ì‚¬ì´ì¦ˆ ì›ì¡°ì»¤í”¼(ICED)\n  - ë¹½ë‹¤ë°©ì˜ BESTë©”ë‰´ë¥¼ ë” í¬ê²Œ ì¦ê²¨ë³´ì„¸ìš” :) [ì£¼ì˜. 564mg ê³ ì¹´í˜ì¸ìœ¼ë¡œ ì¹´í˜ì¸ì— ë¯¼ê°í•œ ì–´ë¦°ì´, ì„ì‚°ë¶€ëŠ” ì„­ì·¨ì— ì£¼ì˜ë°”ëë‹ˆë‹¤]\n  - ê°€ê²©: 4000ì›'), Document(metadata={'source': 'ë¹½ë‹¤ë°©.txt'}, page_content='6. ë¹½ì‚¬ì´ì¦ˆ ì›ì¡°ì»¤í”¼ ì œë¡œìŠˆê±°(ICED)\n  - ë¹½ë‹¤ë°©ì˜ BESTë©”ë‰´ë¥¼ ë” í¬ê²Œ, ì œë¡œìŠˆê±°ë¡œ ì¦ê²¨ë³´ì„¸ìš” :) [ì£¼ì˜. 686mg ê³ ì¹´í˜ì¸ìœ¼ë¡œ ì¹´í˜ì¸ì— ë¯¼ê°í•œ ì–´ë¦°ì´, ì„ì‚°ë¶€ëŠ” ì„­ì·¨ì— ì£¼ì˜ë°”ëë‹ˆë‹¤]\n  - ê°€ê²©: 4000ì›'), Document(metadata={'source': 'ë¹½ë‹¤ë°©.txt'}, page_content='3. ì‚¬ë¼ë‹¤ë¹µ\n  - ë¹½ë‹¤ë°©ì˜ ëŒ€í‘œë©”ë‰´ :) ì¶”ì–µì˜ ê°ì ì‚¬ë¼ë‹¤ë¹µ\n  - ê°€ê²©: 3900ì›'), Document(metadata={'source': 'ë¹½ë‹¤ë°©.txt'}, page_content='2. ë°”ë‹ë¼ë¼ë–¼(ICED)\n  - ë¶€ë“œëŸ¬ìš´ ìš°ìœ ì™€ ë‹¬ì½¤í•˜ê³  ì€ì€í•œ ë°”ë‹ë¼ê°€ ì¡°í™”ë¥¼ ì´ë£¨ëŠ” ìŒë£Œ\n  - ê°€ê²©: 4200ì›')]"

3ë‹¨ê³„. Prompt
~~~~~~~~~~~~~~~~~~~~

:doc:`../glance` ì—ì„œëŠ” ëª¨ë“  ì§€ì‹ì„ í•œ ë²ˆì— í”„ë¡¬í”„íŠ¸ì— ì£¼ì…í–ˆì—ˆì—ˆêµ¬ìš”.

ì´ë²ˆì—ëŠ” "ë¹½ë‹¤ë°© ì¹´í˜ì¸ì´ ë†’ì€ ìŒë£Œì™€ ê°€ê²©ì€?" ì§ˆë¬¸ê³¼ ìœ ì‚¬í•œ ë¬¸ì„œë¡œë§Œ ì˜ ê²€ìƒ‰ì´ ë˜ì—ˆê³  ì´ë¥¼ í”„ë¡¬í”„íŠ¸ì— ì£¼ì…í•˜ê² ìŠµë‹ˆë‹¤.

.. code-block:: python
   :linenos:

   res = client.chat.completions.create(
       messages=[
           {
               "role": "system",
               "content": f"ë„Œ AI Assistant. ëª¨ë¥´ëŠ” ê±´ ëª¨ë¥¸ë‹¤ê³  ëŒ€ë‹µ.\n\n[[ë¹½ë‹¤ë°© ë©”ë‰´ ì •ë³´]]\n{ì§€ì‹}",
           },
           {
               "role": "user",
               "content": question,
           },
       ],
       model="gpt-4o-mini",
       temperature=0,
   )
   print()
   print("[AI]", res.choices[0].message.content)
   print_prices(res.usage.prompt_tokens, res.usage.completion_tokens)

RAG ë‹µë³€ì„ ë°›ì•„ë³´ë©´, ê²€ìƒ‰ëœ ì§€ì‹ì— ê¸°ë°˜í•´ì„œ ì •í™•í•œ ë‹µë³€ì„ ë°›ì•˜ìŒì„ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ğŸ˜‰

.. code-block:: text

   [AI] ë¹½ë‹¤ë°©ì—ì„œ ì¹´í˜ì¸ì´ ë†’ì€ ìŒë£ŒëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

   1. ë¹½ì‚¬ì´ì¦ˆ ì›ì¡°ì»¤í”¼(ICED) - 564mg ê³ ì¹´í˜ì¸, ê°€ê²©: 4000ì›
   2. ë¹½ì‚¬ì´ì¦ˆ ì›ì¡°ì»¤í”¼ ì œë¡œìŠˆê±°(ICED) - 686mg ê³ ì¹´í˜ì¸, ê°€ê²©: 4000ì›

   ì´ ë‘ ìŒë£Œê°€ ì¹´í˜ì¸ì´ ê°€ì¥ ë†’ìŠµë‹ˆë‹¤.
   input: tokens 293, krw 0.0659
   output: tokens 93, krw 0.083700

ì „ì²´ ì½”ë“œ
---------------

``VectorStore.make`` ë©”ì„œë“œ ë‚´ì—ì„œ ``metadata``\ë¥¼ ì¶”ê°€ë¡œ ì €ì¥í•˜ê³ , ``search`` ë©”ì„œë“œì—ì„œë„ ê¸°ì¡´ ë¬¸ì„œì˜ ``metadata``\ë¥¼ ì¶”ì¶œí•´ì„œ ì‚¬ìš©í† ë¡ ê°œì„ í–ˆìŠµë‹ˆë‹¤.

.. warning::

   ë°ì´í„° í¬ë§·ì´ ë³€ê²½ë˜ì—ˆìœ¼ë¯€ë¡œ ê¸°ì¡´ ``vector_store.pickle`` íŒŒì¼ì„ ì‚­ì œí•˜ì‹œê³  pickle íŒŒì¼ì„ ë‹¤ì‹œ ìƒì„±í•´ì£¼ì„¸ìš”.
   ì¬ìƒì„±í•˜ì§€ ì•Šê³  ê¸°ì¡´ pickle ë°ì´í„°ë¡œ ì‹¤í–‰í•˜ì‹œë©´ ``KeyError: 'metadata'`` ì˜ˆì™¸ê°€ ë°œìƒí•  ê²ƒì…ë‹ˆë‹¤.

.. code-block:: python
   :linenos:

   # ì˜ì¡´ ë¼ì´ë¸ŒëŸ¬ë¦¬ : pip install -U openai langchain scikit-learn numpy

   import pickle
   from pathlib import Path
   from pprint import pprint
   from typing import List

   import numpy as np
   import openai
   from environ import Env
   from langchain_community.utils.math import cosine_similarity
   from langchain_core.documents import Document


   env = Env()
   env.read_env()  # .env íŒŒì¼ì„ í™˜ê²½ë³€ìˆ˜ë¡œì„œ ë¡œë”©


   client = openai.Client()


   def print_prices(input_tokens: int, output_tokens: int) -> None:
       input_price = (input_tokens * 0.150 / 1_000_000) * 1_500
       output_price = (output_tokens * 0.600 / 1_000_000) * 1_500
       print("input: tokens {}, krw {:.4f}".format(input_tokens, input_price))
       print("output: tokens {}, krw {:4f}".format(output_tokens, output_price))


   def load() -> List[Document]:
       file_path = "ë¹½ë‹¤ë°©.txt"
       ì§€ì‹: str = open(file_path, "rt", encoding="utf-8").read()
       docs = [
           Document(
               # ì˜ë¯¸ìˆëŠ” ë©”íƒ€ë°ì´í„°ê°€ ìˆë‹¤ë©´, ë§˜ê» ë” ë‹´ìœ¼ì‹œë©´ ë©ë‹ˆë‹¤.
               metadata={"source": file_path},
               page_content=ì§€ì‹,
           )
       ]
       return docs


   def split(src_doc_list: List[Document]) -> List[Document]:
       new_doc_list = []
       for doc in src_doc_list:
           for new_page_content in doc.page_content.split("\n\n"):
               new_doc_list.append(
                   Document(
                       metadata=doc.metadata.copy(),
                       page_content=new_page_content,
                   )
               )
       return new_doc_list


   class VectorStore(list):
       embedding_model = "text-embedding-3-small"

       @classmethod
       def make(cls, doc_list: List[Document]) -> "VectorStore":
           vector_store = cls()

           for doc in doc_list:
               response = client.embeddings.create(
                   model=cls.embedding_model,
                   input=doc.page_content,
               )
               vector_store.append(
                   {
                       "document": doc.model_copy(),
                       "embedding": response.data[0].embedding,
                   }
               )

           return vector_store

       def save(self, vector_store_path: Path) -> None:
           """
           ë²¡í„° ìŠ¤í† ì–´ ë¬¸ì„œ/ì„ë² ë”© ë°ì´í„°ë¥¼ ì§€ì • ê²½ë¡œì— íŒŒì¼ë¡œ ì €ì¥
           """
           with vector_store_path.open("wb") as f:
               # ë¦¬ìŠ¤íŠ¸(self)ë¥¼ pickle í¬ë§·ìœ¼ë¡œ íŒŒì¼(f)ì— ì €ì¥
               pickle.dump(self, f)

       @classmethod
       def load(cls, vector_store_path: Path) -> "VectorStore":
           """
           ì§€ì • ê²½ë¡œì˜ íŒŒì¼ì„ ì½ì–´ì„œ ë²¡í„° ìŠ¤í† ì–´ ë¬¸ì„œ/ì„ë² ë”© ë°ì´í„° ë³µì›
           """
           with vector_store_path.open("rb") as f:
               # pickle í¬ë§·ìœ¼ë¡œ íŒŒì¼(f)ì—ì„œ ë¦¬ìŠ¤íŠ¸(VectorStore)ë¥¼ ë¡œë”©
               return pickle.load(f)

       def search(self, question: str, k: int = 4) -> List[Document]:
           """
           ì§ˆì˜ ë¬¸ìì—´ì„ ë°›ì•„ì„œ, ë²¡í„° ìŠ¤í† ì–´ì—ì„œ ìœ ì‚¬ ë¬¸ì„œë¥¼ ìµœëŒ€ kê°œ ë°˜í™˜
           """

           # ì§ˆë¬¸ ë¬¸ìì—´ì„ ì„ë² ë”© ë²¡í„° ë°°ì—´ë¡œ ë³€í™˜
           response = client.embeddings.create(
               model=self.embedding_model,
               input=question,
           )
           question_embedding = response.data[0].embedding  # 1536 ì°¨ì›, float ë°°ì—´

           # VectorStore ë‚´ì— ì €ì¥ëœ ëª¨ë“  ë¬¸ìì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ì¶”ì¶œ
           embedding_list = [row["embedding"] for row in self]

           # ëª¨ë“  ë°ì´í„°ì™€ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
           similarities = cosine_similarity([question_embedding], embedding_list)[0]
           # ìœ ì‚¬ë„ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ k ê°œ ì„ íƒ
           top_indices = np.argsort(similarities)[::-1][:k]

           # ìƒìœ„ k ê°œ ë¬¸ì„œë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜
           return [
               self[idx]["document"].model_copy()
               for idx in top_indices
           ]

ìœ„ì—ì„œ ìƒì„±ëœ VectorStore í´ë˜ìŠ¤ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

.. code-block:: python
   :linenos:

   def main():
       vector_store_path = Path("vector_store.pickle")

       # ì²«ë²ˆì§¸ ì‹¤í–‰ì—ì„œëŠ” vector_store.pickle íŒŒì¼ì´ ì—†ìœ¼ë¯€ë¡œ load, split, make, save ìˆœì„œë¡œ ë°ì´í„°ë¥¼ ìƒì„±í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.
       if not vector_store_path.is_file():
           doc_list = load()
           print(f"loaded {len(doc_list)} documents")
           doc_list = split(doc_list)
           print(f"split into {len(doc_list)} documents")
           vector_store = VectorStore.make(doc_list)
           vector_store.save(vector_store_path)
           print(f"created {len(vector_store)} items in vector store")
       # ì´í›„ ì‹¤í–‰ì—ì„œëŠ” vector_store.pickle íŒŒì¼ì´ ìˆìœ¼ë¯€ë¡œ load ìˆœì„œë¡œ ë°ì´í„°ë¥¼ ë¡œë”©í•©ë‹ˆë‹¤.
       else:
           vector_store = VectorStore.load(vector_store_path)
           print(f"loaded {len(vector_store)} items in vector store")

       question = "ë¹½ë‹¤ë°© ì¹´í˜ì¸ì´ ë†’ì€ ìŒë£Œì™€ ê°€ê²©ì€?"

       search_doc_list: List[Document] = vector_store.search(question)
       pprint(search_doc_list)

       print("## ì§€ì‹ ##")
       ì§€ì‹: str = str(search_doc_list)
       print(repr(ì§€ì‹))

       res = client.chat.completions.create(
           messages=[
               {
                   "role": "system",
                   "content": f"ë„Œ AI Assistant. ëª¨ë¥´ëŠ” ê±´ ëª¨ë¥¸ë‹¤ê³  ëŒ€ë‹µ.\n\n[[ë¹½ë‹¤ë°© ë©”ë‰´ ì •ë³´]]\n{ì§€ì‹}",
               },
               {
                   "role": "user",
                   "content": question,
               },
           ],
           model="gpt-4o-mini",
           temperature=0,
       )
       print_prices(res.usage.prompt_tokens, res.usage.completion_tokens)
       ai_message = res.choices[0].message.content

       print("[AI]", ai_message)


   if __name__ == "__main__":
       main()

ì‹¤í–‰ê²°ê³¼ëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

.. code-block:: text

   loaded 1 documents
   split into 10 documents
   created 10 items in vector store
   [Document(metadata={'source': 'ë¹½ë‹¤ë°©.txt'}, page_content='5. ë¹½ì‚¬ì´ì¦ˆ ì›ì¡°ì»¤í”¼(ICED)\n  - ë¹½ë‹¤ë°©ì˜ BESTë©”ë‰´ë¥¼ ë” í¬ê²Œ ì¦ê²¨ë³´ì„¸ìš” :) [ì£¼ì˜. 564mg ê³ ì¹´í˜ì¸ìœ¼ë¡œ ì¹´í˜ì¸ì— ë¯¼ê°í•œ ì–´ë¦°ì´, ì„ì‚°ë¶€ëŠ” ì„­ì·¨ì— ì£¼ì˜ë°”ëë‹ˆë‹¤]\n  - ê°€ê²©: 4000ì›'),
    Document(metadata={'source': 'ë¹½ë‹¤ë°©.txt'}, page_content='6. ë¹½ì‚¬ì´ì¦ˆ ì›ì¡°ì»¤í”¼ ì œë¡œìŠˆê±°(ICED)\n  - ë¹½ë‹¤ë°©ì˜ BESTë©”ë‰´ë¥¼ ë” í¬ê²Œ, ì œë¡œìŠˆê±°ë¡œ ì¦ê²¨ë³´ì„¸ìš” :) [ì£¼ì˜. 686mg ê³ ì¹´í˜ì¸ìœ¼ë¡œ ì¹´í˜ì¸ì— ë¯¼ê°í•œ ì–´ë¦°ì´, ì„ì‚°ë¶€ëŠ” ì„­ì·¨ì— ì£¼ì˜ë°”ëë‹ˆë‹¤]\n  - ê°€ê²©: 4000ì›'),
    Document(metadata={'source': 'ë¹½ë‹¤ë°©.txt'}, page_content='3. ì‚¬ë¼ë‹¤ë¹µ\n  - ë¹½ë‹¤ë°©ì˜ ëŒ€í‘œë©”ë‰´ :) ì¶”ì–µì˜ ê°ì ì‚¬ë¼ë‹¤ë¹µ\n  - ê°€ê²©: 3900ì›'),
    Document(metadata={'source': 'ë¹½ë‹¤ë°©.txt'}, page_content='2. ë°”ë‹ë¼ë¼ë–¼(ICED)\n  - ë¶€ë“œëŸ¬ìš´ ìš°ìœ ì™€ ë‹¬ì½¤í•˜ê³  ì€ì€í•œ ë°”ë‹ë¼ê°€ ì¡°í™”ë¥¼ ì´ë£¨ëŠ” ìŒë£Œ\n  - ê°€ê²©: 4200ì›')]
   ## ì§€ì‹ ##
   "[Document(metadata={'source': 'ë¹½ë‹¤ë°©.txt'}, page_content='5. ë¹½ì‚¬ì´ì¦ˆ ì›ì¡°ì»¤í”¼(ICED)\n  - ë¹½ë‹¤ë°©ì˜ BESTë©”ë‰´ë¥¼ ë” í¬ê²Œ ì¦ê²¨ë³´ì„¸ìš” :) [ì£¼ì˜. 564mg ê³ ì¹´í˜ì¸ìœ¼ë¡œ ì¹´í˜ì¸ì— ë¯¼ê°í•œ ì–´ë¦°ì´, ì„ì‚°ë¶€ëŠ” ì„­ì·¨ì— ì£¼ì˜ë°”ëë‹ˆë‹¤]\n  - ê°€ê²©: 4000ì›'), Document(metadata={'source': 'ë¹½ë‹¤ë°©.txt'}, page_content='6. ë¹½ì‚¬ì´ì¦ˆ ì›ì¡°ì»¤í”¼ ì œë¡œìŠˆê±°(ICED)\n  - ë¹½ë‹¤ë°©ì˜ BESTë©”ë‰´ë¥¼ ë” í¬ê²Œ, ì œë¡œìŠˆê±°ë¡œ ì¦ê²¨ë³´ì„¸ìš” :) [ì£¼ì˜. 686mg ê³ ì¹´í˜ì¸ìœ¼ë¡œ ì¹´í˜ì¸ì— ë¯¼ê°í•œ ì–´ë¦°ì´, ì„ì‚°ë¶€ëŠ” ì„­ì·¨ì— ì£¼ì˜ë°”ëë‹ˆë‹¤]\n  - ê°€ê²©: 4000ì›'), Document(metadata={'source': 'ë¹½ë‹¤ë°©.txt'}, page_content='3. ì‚¬ë¼ë‹¤ë¹µ\n  - ë¹½ë‹¤ë°©ì˜ ëŒ€í‘œë©”ë‰´ :) ì¶”ì–µì˜ ê°ì ì‚¬ë¼ë‹¤ë¹µ\n  - ê°€ê²©: 3900ì›'), Document(metadata={'source': 'ë¹½ë‹¤ë°©.txt'}, page_content='2. ë°”ë‹ë¼ë¼ë–¼(ICED)\n  - ë¶€ë“œëŸ¬ìš´ ìš°ìœ ì™€ ë‹¬ì½¤í•˜ê³  ì€ì€í•œ ë°”ë‹ë¼ê°€ ì¡°í™”ë¥¼ ì´ë£¨ëŠ” ìŒë£Œ\n  - ê°€ê²©: 4200ì›')]"
   input: tokens 360, krw 0.0810
   output: tokens 115, krw 0.103500
   [AI] ë¹½ë‹¤ë°©ì—ì„œ ì¹´í˜ì¸ì´ ë†’ì€ ìŒë£ŒëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

   1. **ë¹½ì‚¬ì´ì¦ˆ ì›ì¡°ì»¤í”¼(ICED)**
      - ì¹´í˜ì¸: 564mg
      - ê°€ê²©: 4000ì›

   2. **ë¹½ì‚¬ì´ì¦ˆ ì›ì¡°ì»¤í”¼ ì œë¡œìŠˆê±°(ICED)**
      - ì¹´í˜ì¸: 686mg
      - ê°€ê²©: 4000ì›

   ì´ ë‘ ìŒë£ŒëŠ” ì¹´í˜ì¸ í•¨ëŸ‰ì´ ë†’ìœ¼ë‹ˆ ì„­ì·¨ì— ì£¼ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.

ë§ˆë¬´ë¦¬
------

ì¶•í•˜ë“œë¦½ë‹ˆë‹¤. RAG ê³¼ì •ì„ ë°”ë‹¥ë¶€í„° êµ¬í˜„í•´ë³´ì…¨ìŠµë‹ˆë‹¤. ğŸ‰

RAGì— ëŒ€í•œ ì´í•´ê°€ ë§Œë“¤ì–´ì§€ì…¨ìœ¼ë‹ˆ, ì´ì œ :doc:`./langchain` ë¥¼ ì‚´í´ë³´ì‹œë©´ ê°ê°ì˜ ë™ì‘ì´ ë³´ì´ê³ , ë” ì‰½ê²Œ êµ¬í˜„í•  ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤.