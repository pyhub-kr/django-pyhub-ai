# #02. ì§€ì‹ ì¤€ë¹„ ë‹¨ê³„

```{figure} ./assets/typical-indexing.png
:alt: (RAG) Indexing

ì¶œì²˜ : [ë­ì²´ì¸ ê³µì‹ íŠœí† ë¦¬ì–¼: RAG ì• í”Œë¦¬ì¼€ì´ì…˜ êµ¬ì¶•í•˜ê¸°](https://python.langchain.com/docs/tutorials/rag/)
```

1. Load : ë¬¸ì„œë¥¼ íŒŒì´ì¬ ê°ì²´ë¡œ ë³€í™˜
2. Split : ê° ë¬¸ì„œë“¤ì„ ì˜ë¯¸ìˆëŠ” ë‹¨ìœ„ë¡œ ì¬êµ¬ì„±
3. Embed : ê° ë¬¸ì„œë“¤ì„ ìˆ«ì(ì„ë² ë”© ë°ì´í„°)ë¡œ ë³€í™˜í•˜ì—¬, ì§ˆë¬¸ê³¼ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•  ì¤€ë¹„
    - ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ì°¾ê¸° ìœ„í•´, ì§ˆë¬¸ê³¼ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ëŠ” ë°©ë²•ì€ í˜„ì¬ RAGì—ì„œ ë§ì´ ì‚¬ìš©ë˜ëŠ” ë°©ë²•ì´ë©°, í–¥í›„ ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ëŒ€ì²´ë  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
4. Store : ìœ ì‚¬ë„ ë°ì´í„°ë¥¼ ë””ìŠ¤í¬ì— ì €ì¥í•˜ì—¬, ê³„ì† ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì¤€ë¹„
    - ë¬¸ì„œ ë‚´ìš©ì´ ë°”ë€Œë©´, ì„ë² ë”© ë°ì´í„°ë„ ë§¤ë²ˆ ì¬ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.

## 1ë‹¨ê³„. Load - PDF/TXT/HTML ì§€ì‹ë“¤ì„ ì¼ê´€ëœ íŒŒì´ì¬ ê°ì²´ë¡œ ë³€í™˜

ë°˜í™˜ íƒ€ì… : `List[Document]`

ë­ì²´ì¸ì—ì„œëŠ” ë‹¤ì–‘í•œ í¬ë§·ì˜ íŒŒì¼ë“¤ì— ëŒ€í•´ì„œ ì¼ê´€ëœ ì¸í„°í˜ì´ìŠ¤ë¡œ íŒŒì´ì¬ ê°ì²´ë¡œ ë³€í™˜í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•´ì¤ë‹ˆë‹¤. ì´ë¥¼ `Document Loader`ë¼ê³  í•©ë‹ˆë‹¤.

```{admonition} ë­ì²´ì¸ ê³µì‹ë¬¸ì„œ [ë¬¸ì„œ ë¡œë”](https://python.langchain.com/docs/how_to/#document-loaders)
:class: tip

+ [PDF](https://python.langchain.com/docs/how_to/document_loader_pdf/)
+ [ì›¹í˜ì´ì§€](https://python.langchain.com/docs/how_to/document_loader_web/)
+ [CSV](https://python.langchain.com/docs/how_to/document_loader_csv/)
+ [ë¡œì»¬ íŒŒì¼](https://python.langchain.com/docs/how_to/document_loader_directory/)
+ [HTML ë°ì´í„°](https://python.langchain.com/docs/how_to/document_loader_html/)
+ [JSON ë°ì´í„°](https://python.langchain.com/docs/how_to/document_loader_json/)
+ [ë§ˆí¬ë‹¤ìš´ ë°ì´í„°](https://python.langchain.com/docs/how_to/document_loader_markdown/)
+ [ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ ì˜¤í”¼ìŠ¤ ë°ì´í„°](https://python.langchain.com/docs/how_to/document_loader_office_file/)
+ [ì»¤ìŠ¤í…€ ë¬¸ì„œ ë¡œë”](https://python.langchain.com/docs/how_to/document_loader_custom/)
```

[ë¹½ë‹¤ë°©.txt](./ë¹½ë‹¤ë°©.txt) íŒŒì¼ì„ ë¬¸ì„œë¡œ ë³€í™˜í•˜ëŠ” ì½”ë“œë¥¼ 2ê°€ì§€ ë²„ì „ìœ¼ë¡œ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤.

`Load` ë‹¨ê³„ì—ì„œëŠ” ë¬¸ì„œ í¬ë§·ì— ë§ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬, ë¬¸ì„œë¥¼ ì—´ê³  ë©”íƒ€ë°ì´í„°ì™€ ë‚´ìš©ì„ ì½ì–´ì„œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì‹  í›„ì—, `metadata` ì‚¬ì „ì—ëŠ” ê°ì¢… ì •ë³´ë¥¼ ë‹´ê³ , `page_content` ë¬¸ìì—´ì— ë¬¸ì„œ í…ìŠ¤íŠ¸ë¥¼ ë‹´ì•„ì„œ ë°˜í™˜í•©ë‹ˆë‹¤.

+ `metadata` ì‚¬ì „ ê°’ì€ í”„ë¡¬í”„íŠ¸ì— ë¬¸ìì—´ë¡œì„œ ì „ë‹¬ë©ë‹ˆë‹¤.
    - ê·¸ëŸ¬ë‹ˆ ì–´ë–¤ `Key`ê°€ ì§€ì›ë˜ëŠ” ì§€ì— ëŒ€í•´ì„œëŠ” ê³ ë¯¼í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤.
    - ë¬¸ì„œì™€ ê´€ë ¨ëœ ì •ë³´ë¼ë©´ ì–´ë–¤ ì •ë³´ë“  ì €ì¥í•˜ì‹œë©´ ë©ë‹ˆë‹¤. ë¬¸ì„œ ë‚´ìš©ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ë½‘ì•„ì„œ `keywords` í‚¤ë¡œ ì €ì¥í•˜ê±°ë‚˜, ìš”ì•½ì„ `summary` í‚¤ë¡œ ì €ì¥í•˜ê¸°ë„ í•©ë‹ˆë‹¤.
    - PDF Loader ê²½ìš°ì—ë„ PDF Loader ì¢…ë¥˜ì— ë”°ë¼ ì„¤ì •í•´ì£¼ëŠ” ë©”íƒ€ ë°ì´í„°ê°€ ë‹¤ë¦…ë‹ˆë‹¤.

::::{tab-set}

:::{tab-item} íŒŒì´ì¬ ì½”ë“œë¡œ ê°„ê²°í•˜ê²Œ ë¬¸ì„œ ë³€í™˜

```{code-block} python
:linenos:

from typing import List
from pprint import pprint
from langchain_core.documents import Document

def load() -> List[Document]:
    file_path = "ë¹½ë‹¤ë°©.txt"
    ì§€ì‹: str = open(file_path, "rt", encoding="utf-8").read()
    docs = [
        Document(
            # ì˜ë¯¸ìˆëŠ” ë©”íƒ€ë°ì´í„°ê°€ ìˆë‹¤ë©´, ë§˜ê» ë” ë‹´ìœ¼ì‹œë©´ ë©ë‹ˆë‹¤.
            metadata={"source": file_path},
            page_content=ì§€ì‹,
        )
    ]
    return docs

doc_list = load()
print(f"loaded {len(doc_list)} documents")
pprint(doc_list)
```
:::

:::{tab-item} ë­ì²´ì¸ì„ í™œìš©í•´ì„œ ë¬¸ì„œ ë³€í™˜

```{code-block} python
:linenos:
:emphasize-lines: 5-7,10-12

from typing import List
from pprint import pprint
from langchain_core.documents import Document

# ì˜ˆì „ì—ëŠ” `langchain` ë¼ì´ë¸ŒëŸ¬ë¦¬ ê¸°ë³¸ì—ì„œ ë‹¤ì–‘í•œ `Loader`ë¥¼ ì§€ì›í–ˆì§€ë§Œ,
# ìš”ì¦˜ì€ `langchain-community` ë¼ì´ë¸ŒëŸ¬ë¦¬ ë“± ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ì§€ì›í•˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.
from langchain_community.document_loaders import TextLoader

def load() -> List[Document]:
    file_path = "ë¹½ë‹¤ë°©.txt"
    loader = TextLoader(file_path=file_path)
    docs: List[Document] = loader.load()
    return docs

doc_list = load()
print(f"loaded {len(doc_list)} documents")
pprint(doc_list)
```
:::

::::

ë‘ ì½”ë“œ ëª¨ë‘ ë™ì¼í•œ ì¶œë ¥ì„ ë°˜í™˜í•©ë‹ˆë‹¤.

```{code-block} text
loaded 1 documents
[Document(metadata={'source': 'ë¹½ë‹¤ë°©.txt'}, page_content='1. ì•„ì´ìŠ¤í‹°ìƒ·ì¶”ê°€(ì•„.ìƒ·.ì¶”)\n  - SNSì—ì„œ ë” ìœ ëª…í•œ ê¿€íŒ ì¡°í•© ìŒë£Œ :) ìƒì½¤ë‹¬ì½¤í•œ ë³µìˆ­ì•„ë§› ì•„ì´ìŠ¤í‹°ì— ì§„í•œ ì—ìŠ¤í”„ë ˆì†Œ ìƒ·ì´ ì–´ìš°ëŸ¬ì ¸ í™˜ìƒì¡°í•©\n  - ê°€ê²©: 3800ì›\n\n2. ë°”ë‹ë¼ë¼ë–¼(ICED)\n  - ë¶€ë“œëŸ¬ìš´ ìš°ìœ ì™€ ë‹¬ì½¤í•˜ê³  ì€ì€í•œ ë°”ë‹ë¼ê°€ ì¡°í™”ë¥¼ ì´ë£¨ëŠ” ìŒë£Œ\n  - ê°€ê²©: 4200ì›\n\n3. ì‚¬ë¼ë‹¤ë¹µ\n  - ë¹½ë‹¤ë°©ì˜ ëŒ€í‘œë©”ë‰´ :) ì¶”ì–µì˜ ê°ì ì‚¬ë¼ë‹¤ë¹µ\n  - ê°€ê²©: 3900ì›\n\n4. ë¹½ì‚¬ì´ì¦ˆ ì•„ë©”ë¦¬ì¹´ë…¸(ICED)\n  - ì—ìŠ¤í”„ë ˆì†Œ 4ìƒ·ì´ ë“¤ì–´ê°€ ê¹Šê³  ì§„í•œ ë§›ì˜ ì•„ë©”ë¦¬ì¹´ë…¸\n  - ê°€ê²©: 3500ì›\n\n5. ë¹½ì‚¬ì´ì¦ˆ ì›ì¡°ì»¤í”¼(ICED)\n  - ë¹½ë‹¤ë°©ì˜ BESTë©”ë‰´ë¥¼ ë” í¬ê²Œ ì¦ê²¨ë³´ì„¸ìš” :) [ì£¼ì˜. 564mg ê³ ì¹´í˜ì¸ìœ¼ë¡œ ì¹´í˜ì¸ì— ë¯¼ê°í•œ ì–´ë¦°ì´, ì„ì‚°ë¶€ëŠ” ì„­ì·¨ì— ì£¼ì˜ë°”ëë‹ˆë‹¤]\n  - ê°€ê²©: 4000ì›\n\n6. ë¹½ì‚¬ì´ì¦ˆ ì›ì¡°ì»¤í”¼ ì œë¡œìŠˆê±°(ICED)\n  - ë¹½ë‹¤ë°©ì˜ BESTë©”ë‰´ë¥¼ ë” í¬ê²Œ, ì œë¡œìŠˆê±°ë¡œ ì¦ê²¨ë³´ì„¸ìš” :) [ì£¼ì˜. 686mg ê³ ì¹´í˜ì¸ìœ¼ë¡œ ì¹´í˜ì¸ì— ë¯¼ê°í•œ ì–´ë¦°ì´, ì„ì‚°ë¶€ëŠ” ì„­ì·¨ì— ì£¼ì˜ë°”ëë‹ˆë‹¤]\n  - ê°€ê²©: 4000ì›\n\n7. ë¹½ì‚¬ì´ì¦ˆ ë‹¬ì½¤ì•„ì´ìŠ¤í‹°(ICED)\n  - ë¹½ë‹¤ë°©ì˜ BESTë©”ë‰´ë¥¼ ë” í¬ê²Œ ì¦ê²¨ë³´ì„¸ìš” :) ì‹œì›í•œ ë³µìˆ­ì•„ë§› ì•„ì´ìŠ¤í‹°\n  - ê°€ê²©: 4300ì›\n\n8. ë¹½ì‚¬ì´ì¦ˆ ì•„ì´ìŠ¤í‹°ìƒ·ì¶”ê°€(ICED)\n  - SNSì—ì„œ ë” ìœ ëª…í•œ ê¿€íŒ ì¡°í•© ìŒë£Œ :) ìƒì½¤ë‹¬ì½¤í•œ ë³µìˆ­ì•„ë§› ì•„ì´ìŠ¤í‹°ì— ì§„í•œ ì—ìŠ¤í”„ë ˆì†Œ 2ìƒ·ì´ ì–´ìš°ëŸ¬ì ¸ í™˜ìƒì¡°í•©\n  - ê°€ê²©: 4800ì›\n\n9. ë¹½ì‚¬ì´ì¦ˆ ì•„ì´ìŠ¤í‹° ë§ê³ ì¶”ê°€+ë…¸ë€ë¹¨ëŒ€\n  - SNSí•«ë©”ë‰´ ì•„ì´ìŠ¤í‹°ì— ë§ê³ ë¥¼ í•œê°€ë“:)\n  - ê°€ê²©: 6300ì›\n\n10. ë¹½ì‚¬ì´ì¦ˆ ì´ˆì½”ë¼ë–¼(ICED)\n  - ë¹½ë‹¤ë°©ì˜ BESTë©”ë‰´ë¥¼ ë” í¬ê²Œ ì¦ê²¨ë³´ì„¸ìš” :) ì§„ì§œ~ì™„~ì „ ì§„í•œ ì´ˆì½”ë¼ë–¼\n  - ê°€ê²© : 5500ì›\n')]
```

RAG ì—ì„œëŠ” ì§ˆë¬¸ê³¼ ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ ë¬¸ì„œ ë‹¨ìœ„ë¡œ ì°¾ì•„ì„œ, í”„ë¡¬í”„íŠ¸ì— ì ìš©í•©ë‹ˆë‹¤.
ê°ê°ì˜ ë¬¸ì„œëŠ” ì•„ë˜ ì¡°ê±´ì„ ë§Œì¡±í•˜ë©´, ë³´ë‹¤ ì¢‹ì€ RAG ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

1. í•œ ë¬¸ì„œì— ì—¬ëŸ¬ ì£¼ì œê°€ ì„ì—¬ ìˆì§€ ì•Šê³ , ë‹¨ì¼ í•µì‹¬ ì •ë³´ë¥¼ ì ì ˆí•œ í¬ê¸°ë¡œ í¬í•¨í•  ê²ƒ
    - ë¶ˆí•„ìš”í•œ ì •ë³´ê¹Œì§€ í•¨ê»˜ ì œê³µí•˜ê²Œ ë©ë‹ˆë‹¤.
    - ë¬¸ì„œì˜ ë‚´ìš©ì´ ë„ˆë¬´ ì§§ê±°ë‚˜ ë¶€ì¡±í•˜ë©´, ì—¬ëŸ¬ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•´ì•¼ í•˜ë¯€ë¡œ RAG ì„±ëŠ¥ì´ ì €í•˜ë©ë‹ˆë‹¤.
2. ì¼ì •í•œ êµ¬ì¡°ë¥¼ ìœ ì§€í•  ê²ƒ
3. ê´€ë ¨ì—†ëŠ” ì •ë³´ë¥¼ ì œê±°í•  ê²ƒ
4. ë‹¤ë¥¸ ë¬¸ì„œì™€ ì¤‘ë³µë˜ì§€ ì•Šë„ë¡ êµ¬ì„±í•  ê²ƒ
5. ì ì ˆí•œ ë©”íƒ€ ë°ì´í„°ë¥¼ í¬í•¨í•  ê²ƒ

```{admonition} ë³´ë‹¤ ì¢‹ì€ RAG ê²°ê³¼ë¥¼ ì–»ê¸° ìœ„í•´ì„œëŠ”.
:class: warning

ì›ë³¸ ì§€ì‹ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•  ë•Œ, ë‹¨ìˆœíˆ íŒŒì¼ ë‚´ìš©ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” ê²ƒë§Œìœ¼ë¡œëŠ” ì¶©ë¶„í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ë­ì²´ì¸(LangChain)ì„ ì‚¬ìš©í•˜ë“  ì§ì ‘ êµ¬í˜„í•˜ë“ , ë³€í™˜ëœ í…ìŠ¤íŠ¸ ë¬¸ì„œê°€ íš¨ê³¼ì ìœ¼ë¡œ ê²€ìƒ‰ë˜ê³  í™œìš©ë  ìˆ˜ ìˆë„ë¡ êµ¬ì¡°í™”í•˜ê³  ìµœì í™”í•˜ì—¬,
**ì›ë³¸ ì§€ì‹ ë°ì´í„°ì˜ í’ˆì§ˆì„ ê´€ë¦¬í•˜ëŠ” ê²ƒ**ì´ í•µì‹¬ì…ë‹ˆë‹¤.

í•˜ì§€ë§Œ, ì›ë³¸ ì§€ì‹ ë°ì´í„°ê°€ ë°©ëŒ€í•  ê²½ìš° ê° ë¬¸ì„œì˜ ë‚´ìš©ì„ ì¼ì¼ì´ ì¡°ì •í•˜ê³  ê²€ìˆ˜í•˜ëŠ” ê²ƒì€ ì–´ë ¤ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
```

## 2ë‹¨ê³„. Split - ê° ë¬¸ì„œë“¤ì„ ìª¼ê°œê¸°

`Load` ë‹¨ê³„ì—ì„œ ìƒì„±ëœ ë¬¸ì„œë¥¼ ìª¼ê°œì–´ ì—¬ëŸ¬ ë¬¸ì„œë¡œ ë‚˜ëˆ„ëŠ” `Split` ë‹¨ê³„ì…ë‹ˆë‹¤.
ë¬¸ì„œì˜ ë‚´ìš©ì„ ë³€ê²½í•˜ëŠ” ê²ƒì€ ì•„ë‹ˆêµ¬ìš”. ë¬¸ì„œì˜ í¬ë§·ì€ ìœ ì§€í•œ ì±„ ë¬¸ì„œë¥¼ ìª¼ê°œì–´ ì—¬ëŸ¬ ë¬¸ì„œë¡œ ë‚˜ëˆ„ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.

+ í•˜ë‚˜ì˜ ë¬¸ì„œê°€ ë„ˆë¬´ ê¸¸ë©´, LLM ëª¨ë¸ì— ì „ë‹¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
+ í•˜ë‚˜ì˜ ë¬¸ì„œê°€ ë„ˆë¬´ ê¸¸ë©´, LLMì—ì„œ ë„ˆë¬´ ë§ì€ ì •ë³´ë¥¼ í¬ì°©í•˜ë ¤ê³  í•©ë‹ˆë‹¤.
+ í•˜ë‚˜ì˜ ë¬¸ì„œì— ì—¬ëŸ¬ ì£¼ì œê°€ ì„ì—¬ ìˆëŠ” ê²½ìš°, ê° ì£¼ì œë¥¼ ìª¼ê°œì–´ ì—¬ëŸ¬ ë¬¸ì„œë¡œ ë‚˜ëˆ„ëŠ” ê²ƒì´ RAG ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.

```{figure} ./assets/typical-splits.png
:alt: (RAG) Indexing

ì¶œì²˜ : [ë­ì²´ì¸ ê³µì‹ íŠœí† ë¦¬ì–¼: Text Splitters](https://python.langchain.com/docs/concepts/text_splitters/)
```

ì•„ë˜ì™€ ê°™ì´ í•œ ë¬¸ì„œì— ì—¬ëŸ¬ ë©”ë‰´ ì •ë³´ê°€ ì„ì—¬ ìˆë‹¤ë©´ ê° ë©”ë‰´ ì •ë³´ë¥¼ ìª¼ê°œì–´ ì—¬ëŸ¬ ë¬¸ì„œë¡œ ë‚˜ëˆ„ëŠ” ê²ƒì´ RAG ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.

::::{tab-set}

:::{tab-item} ìª¼ê°œê¸° ì „ ë¬¸ì„œë“¤

ì²«ë²ˆì§¸ ë¬¸ì„œì˜ `.page_content`

```{code-block} text

1. ì•„ì´ìŠ¤í‹°ìƒ·ì¶”ê°€(ì•„.ìƒ·.ì¶”)
  - SNSì—ì„œ ë” ìœ ëª…í•œ ê¿€íŒ ì¡°í•© ìŒë£Œ :) ìƒì½¤ë‹¬ì½¤í•œ ë³µìˆ­ì•„ë§› ì•„ì´ìŠ¤í‹°ì— ì§„í•œ ì—ìŠ¤í”„ë ˆì†Œ ìƒ·ì´ ì–´ìš°ëŸ¬ì ¸ í™˜ìƒì¡°í•©
  - ê°€ê²©: 3800ì›

2. ë°”ë‹ë¼ë¼ë–¼(ICED)
  - ë¶€ë“œëŸ¬ìš´ ìš°ìœ ì™€ ë‹¬ì½¤í•˜ê³  ì€ì€í•œ ë°”ë‹ë¼ê°€ ì¡°í™”ë¥¼ ì´ë£¨ëŠ” ìŒë£Œ
  - ê°€ê²©: 4200ì›

3. ì‚¬ë¼ë‹¤ë¹µ
  - ë¹½ë‹¤ë°©ì˜ ëŒ€í‘œë©”ë‰´ :) ì¶”ì–µì˜ ê°ì ì‚¬ë¼ë‹¤ë¹µ
  - ê°€ê²©: 3900ì›
```

ë‘ë²ˆì§¸ ë¬¸ì„œì˜ `.page_content`

```{code-block} text

4. ë¹½ì‚¬ì´ì¦ˆ ì•„ë©”ë¦¬ì¹´ë…¸(ICED)
  - ì—ìŠ¤í”„ë ˆì†Œ 4ìƒ·ì´ ë“¤ì–´ê°€ ê¹Šê³  ì§„í•œ ë§›ì˜ ì•„ë©”ë¦¬ì¹´ë…¸
  - ê°€ê²©: 3500ì›

5. ë¹½ì‚¬ì´ì¦ˆ ì›ì¡°ì»¤í”¼(ICED)
  - ë¹½ë‹¤ë°©ì˜ BESTë©”ë‰´ë¥¼ ë” í¬ê²Œ ì¦ê²¨ë³´ì„¸ìš” :) [ì£¼ì˜. 564mg ê³ ì¹´í˜ì¸ìœ¼ë¡œ ì¹´í˜ì¸ì— ë¯¼ê°í•œ ì–´ë¦°ì´, ì„ì‚°ë¶€ëŠ” ì„­ì·¨ì— ì£¼ì˜ë°”ëë‹ˆë‹¤]
  - ê°€ê²©: 4000ì›
```
:::

:::{tab-item} ë‚˜ëˆ ì§„ ê° ë¬¸ì„œì˜ `.page_content`

ë‚˜ëˆ ì§„ ë¬¸ì„œì˜ `.page_content`

```{code-block} text

1. ì•„ì´ìŠ¤í‹°ìƒ·ì¶”ê°€(ì•„.ìƒ·.ì¶”)
  - SNSì—ì„œ ë” ìœ ëª…í•œ ê¿€íŒ ì¡°í•© ìŒë£Œ :) ìƒì½¤ë‹¬ì½¤í•œ ë³µìˆ­ì•„ë§› ì•„ì´ìŠ¤í‹°ì— ì§„í•œ ì—ìŠ¤í”„ë ˆì†Œ ìƒ·ì´ ì–´ìš°ëŸ¬ì ¸ í™˜ìƒì¡°í•©
  - ê°€ê²©: 3800ì›
```

ë‚˜ëˆ ì§„ ë¬¸ì„œì˜ `.page_content`

```{code-block} text

2. ë°”ë‹ë¼ë¼ë–¼(ICED)
  - ë¶€ë“œëŸ¬ìš´ ìš°ìœ ì™€ ë‹¬ì½¤í•˜ê³  ì€ì€í•œ ë°”ë‹ë¼ê°€ ì¡°í™”ë¥¼ ì´ë£¨ëŠ” ìŒë£Œ
  - ê°€ê²©: 4200ì›
```

ë‚˜ëˆ ì§„ ë¬¸ì„œì˜ `.page_content`

```{code-block} text

3. ì‚¬ë¼ë‹¤ë¹µ
  - ë¹½ë‹¤ë°©ì˜ ëŒ€í‘œë©”ë‰´ :) ì¶”ì–µì˜ ê°ì ì‚¬ë¼ë‹¤ë¹µ
  - ê°€ê²©: 3900ì›
```

ë‚˜ëˆ ì§„ ë¬¸ì„œì˜ `.page_content`

```{code-block} text

4. ë¹½ì‚¬ì´ì¦ˆ ì•„ë©”ë¦¬ì¹´ë…¸(ICED)
  - ì—ìŠ¤í”„ë ˆì†Œ 4ìƒ·ì´ ë“¤ì–´ê°€ ê¹Šê³  ì§„í•œ ë§›ì˜ ì•„ë©”ë¦¬ì¹´ë…¸
  - ê°€ê²©: 3500ì›
```

ë‚˜ëˆ ì§„ ë¬¸ì„œì˜ `.page_content`

```{code-block} text

5. ë¹½ì‚¬ì´ì¦ˆ ì›ì¡°ì»¤í”¼(ICED)
  - ë¹½ë‹¤ë°©ì˜ BESTë©”ë‰´ë¥¼ ë” í¬ê²Œ ì¦ê²¨ë³´ì„¸ìš” :) [ì£¼ì˜. 564mg ê³ ì¹´í˜ì¸ìœ¼ë¡œ ì¹´í˜ì¸ì— ë¯¼ê°í•œ ì–´ë¦°ì´, ì„ì‚°ë¶€ëŠ” ì„­ì·¨ì— ì£¼ì˜ë°”ëë‹ˆë‹¤]
  - ê°€ê²©: 4000ì›
```
:::

::::

ë¬¸ì„œì˜ ì–‘ì´ ì‘ë‹¤ë©´ ì‚¬ëŒì´ ì¼ì¼ì´ ìª¼ê°¤ ìˆ˜ë„ ìˆê² ì§€ë§Œ, ëŒ€ê°œ ë¬¸ì„œì˜ ì–‘ì´ ë§ê¸° ë•Œë¬¸ì— ì¼ê´„ì ì¸ ë£°ì„ ì ìš©í•´ì„œ ìª¼ê°œëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.
[ë­ì²´ì¸ ê³µì‹ íŠœí† ë¦¬ì–¼](https://python.langchain.com/docs/concepts/text_splitters/#approaches)ì—ì„œëŠ” ë‹¤ìŒ 4ê°€ì§€ ì „ëµì„ ì–¸ê¸‰í•˜ê³  ìˆìŠµë‹ˆë‹¤.

1. **ê¸¸ì´**ì— ê¸°ë°˜í•œ ìª¼ê°œê¸°
    - ì§ê´€ì ì´ê³  êµ¬í˜„ì´ ê°„ë‹¨í•˜ì§€ë§Œ, í…ìŠ¤íŠ¸ êµ¬ì¡°ë‚˜ ì˜ë¯¸ë¥¼ ê³ ë ¤í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ë¬¸ë§¥ ë‹¨ì ˆ ê°€ëŠ¥ì„±ì´ í½ë‹ˆë‹¤.
    - ìœ„ ë°ì´í„°ì²˜ëŸ¼ ê° ë©”ë‰´ë§ˆë‹¤ êµ¬ë¶„ìê°€ `"\n\n"`ì²˜ëŸ¼ ì¼ê´€ë˜ê²Œ ì˜ ì§€ì •ë˜ì–´ìˆìœ¼ë©´, ì¢‹ì€ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    - ë­ì²´ì¸ : [`CharacterTextSplitter`](https://python.langchain.com/api_reference/text_splitters/character/langchain_text_splitters.character.CharacterTextSplitter.html), [`RecursiveCharacterTextSplitter`](https://python.langchain.com/api_reference/text_splitters/character/langchain_text_splitters.character.RecursiveCharacterTextSplitter.html) (ë§ì´ ì‚¬ìš© â­ï¸)
2. **í…ìŠ¤íŠ¸ êµ¬ì¡°**ì— ê¸°ë°˜í•œ ìª¼ê°œê¸°
    - ë¬¸ë‹¨, í—¤ë”, ëª©ë¡ ë“±ì˜ í…ìŠ¤íŠ¸ êµ¬ì¡°ë¥¼ ê³ ë ¤í•´ì„œ ìª¼ê°­ë‹ˆë‹¤.
    - í•˜ì§€ë§Œ ë¬¸ì„œë§ˆë‹¤ í…ìŠ¤íŠ¸ êµ¬ì¡°ê°€ ë‹¤ë¥¼ ìˆ˜ ë°–ì— ì—†ìœ¼ë¯€ë¡œ ì ìš©ì´ ì œí•œì ì…ë‹ˆë‹¤.
    - ë­ì²´ì¸ : [`NltkTextSplitter`](https://python.langchain.com/api_reference/text_splitters/nltk/langchain_text_splitters.nltk.NLTKTextSplitter.html#langchain_text_splitters.nltk.NLTKTextSplitter), [`SpacyTextSplitter`](https://python.langchain.com/api_reference/text_splitters/spacy/langchain_text_splitters.spacy.SpacyTextSplitter.html#langchain_text_splitters.spacy.SpacyTextSplitter) ë“±
3. **ë¬¸ì„œ êµ¬ì¡°**ì— ê¸°ë°˜í•œ ìª¼ê°œê¸°
    - íŠ¹ì • ë¬¸ì„œ í¬ë§· (HTML, Markdown ë“±)ì˜ ê³„ì¸µì  êµ¬ì¡° (ì„¹ì…˜, í•˜ìœ„ ì„¹ì…˜ ë“±)ë¥¼ ê³ ë ¤í•´ì„œ ìª¼ê°­ë‹ˆë‹¤.
    - êµ¬ì¡°ê°€ ë³µì¡í•œ ë¬¸ì„œì¼ìˆ˜ë¡ ë¶„í•  ë¡œì§ì´ ë³µì¡í•´ì§€ê³ , ì¼ë¶€ ì˜ì—­ì€ ëˆ„ë½ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    - ë­ì²´ì¸
        - [`HTMLHeaderTextSplitter`](https://python.langchain.com/api_reference/text_splitters/html/langchain_text_splitters.html.HTMLHeaderTextSplitter.html#langchain_text_splitters.html.HTMLHeaderTextSplitter), [`HTMLSectionSplitter`](https://python.langchain.com/api_reference/text_splitters/html/langchain_text_splitters.html.HTMLSectionSplitter.html)
        - [`MarkdownTextSplitter`](https://python.langchain.com/api_reference/text_splitters/markdown/langchain_text_splitters.markdown.MarkdownTextSplitter.html), [`MarkdownHeaderTextSplitter`](https://python.langchain.com/api_reference/text_splitters/markdown/langchain_text_splitters.markdown.MarkdownHeaderTextSplitter.html), [`ExperimentalMarkdownSyntaxTextSplitter`](https://python.langchain.com/api_reference/text_splitters/markdown/langchain_text_splitters.markdown.ExperimentalMarkdownSyntaxTextSplitter.html) ë“±
4. **ì˜ë¯¸** (Semantic meaning)ì— ê¸°ë°˜í•œ ìª¼ê°œê¸°
    - ì˜ë¯¸ì ìœ¼ë¡œ ì—°ê´€ëœ ë‹¨ë½ì„ í•˜ë‚˜ë¡œ ë¬¶ì–´ ë¬¸ë§¥ì„ ê°€ì¥ ì˜ ìœ ì§€í•˜ë©°, ì¤‘ìš” ë¬¸ë‹¨ë§Œ íš¨ìœ¨ì ìœ¼ë¡œ ì¶”ë ¤ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    - ì˜ë¯¸ ë¶„ì„ì„ ìœ„í•œ ë³„ë„ì˜ í”„ë¡œì„¸ìŠ¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.
    - ë¶„ì„ ê²°ê³¼ê°€ ë¶€ì •í™•í•  ê²½ìš°, ì˜ë„ì™€ ë‹¤ë¥´ê²Œ ë¶„í• ë˜ê±°ë‚˜ ëˆ„ë½ë  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
    - ë­ì²´ì¸
        - [`HTMLSemanticPreservingSplitter`](https://python.langchain.com/api_reference/text_splitters/html/langchain_text_splitters.html.HTMLSemanticPreservingSplitter.html) ë“±

[ë¹½ë‹¤ë°©.txt](./ë¹½ë‹¤ë°©.txt) ë°ì´í„°ëŠ” ê° ë©”ë‰´ê°€ êµ¬ë¶„ìë¡œ `"\n\n"`ë¡œ êµ¬ë¶„ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‹ˆ ì•„ë˜ì™€ ê°™ì´ ë¬¸ìì—´ì˜ `.split("\n\n")` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•´ì„œ ë¬¸ì„œ ë‚´ìš©ì„ ìª¼ê°¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìª¼ê°œì–´ì§„ ë¬¸ì„œëŠ” ì›ë³¸ ë¬¸ì„œì˜ ë©”íƒ€ ë°ì´í„°ë¥¼ ê·¸ëŒ€ë¡œ ê°€ì ¸ê°‘ë‹ˆë‹¤.

```{code-block} python
:linenos:
:emphasize-lines: 1-11,15-16

def split(src_doc_list: List[Document]) -> List[Document]:
    new_doc_list = []
    for doc in src_doc_list:
        for new_page_content in doc.page_content.split("\n\n"):
            new_doc_list.append(
                Document(
                    metadata=doc.metadata.copy(),
                    page_content=new_page_content,
                )
            )
    return new_doc_list

doc_list = load()
print(f"loaded {len(doc_list)} documents")
doc_list = split(doc_list)
print(f"split into {len(doc_list)} documents")
# pprint(doc_list)
```

ì‹¤í–‰í•´ë³´ì‹œë©´, ì•„ë˜ì™€ ê°™ì´ ê° ë©”ë‰´ë“¤ì´ ê°ê°ì˜ ë¬¸ì„œë¡œ ìª¼ê°œì§„ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```{code-block} text
[Document(metadata={'source': 'ë¹½ë‹¤ë°©.txt'}, page_content='1. ì•„ì´ìŠ¤í‹°ìƒ·ì¶”ê°€(ì•„.ìƒ·.ì¶”)\n  - SNSì—ì„œ ë” ìœ ëª…í•œ ê¿€íŒ ì¡°í•© ìŒë£Œ :) ìƒì½¤ë‹¬ì½¤í•œ ë³µìˆ­ì•„ë§› ì•„ì´ìŠ¤í‹°ì— ì§„í•œ ì—ìŠ¤í”„ë ˆì†Œ ìƒ·ì´ ì–´ìš°ëŸ¬ì ¸ í™˜ìƒì¡°í•©\n  - ê°€ê²©: 3800ì›'),
 Document(metadata={'source': 'ë¹½ë‹¤ë°©.txt'}, page_content='2. ë°”ë‹ë¼ë¼ë–¼(ICED)\n  - ë¶€ë“œëŸ¬ìš´ ìš°ìœ ì™€ ë‹¬ì½¤í•˜ê³  ì€ì€í•œ ë°”ë‹ë¼ê°€ ì¡°í™”ë¥¼ ì´ë£¨ëŠ” ìŒë£Œ\n  - ê°€ê²©: 4200ì›'),
 Document(metadata={'source': 'ë¹½ë‹¤ë°©.txt'}, page_content='3. ì‚¬ë¼ë‹¤ë¹µ\n  - ë¹½ë‹¤ë°©ì˜ ëŒ€í‘œë©”ë‰´ :) ì¶”ì–µì˜ ê°ì ì‚¬ë¼ë‹¤ë¹µ\n  - ê°€ê²©: 3900ì›'),
 Document(metadata={'source': 'ë¹½ë‹¤ë°©.txt'}, page_content='4. ë¹½ì‚¬ì´ì¦ˆ ì•„ë©”ë¦¬ì¹´ë…¸(ICED)\n  - ì—ìŠ¤í”„ë ˆì†Œ 4ìƒ·ì´ ë“¤ì–´ê°€ ê¹Šê³  ì§„í•œ ë§›ì˜ ì•„ë©”ë¦¬ì¹´ë…¸\n  - ê°€ê²©: 3500ì›'),
 Document(metadata={'source': 'ë¹½ë‹¤ë°©.txt'}, page_content='5. ë¹½ì‚¬ì´ì¦ˆ ì›ì¡°ì»¤í”¼(ICED)\n  - ë¹½ë‹¤ë°©ì˜ BESTë©”ë‰´ë¥¼ ë” í¬ê²Œ ì¦ê²¨ë³´ì„¸ìš” :) [ì£¼ì˜. 564mg ê³ ì¹´í˜ì¸ìœ¼ë¡œ ì¹´í˜ì¸ì— ë¯¼ê°í•œ ì–´ë¦°ì´, ì„ì‚°ë¶€ëŠ” ì„­ì·¨ì— ì£¼ì˜ë°”ëë‹ˆë‹¤]\n  - ê°€ê²©: 4000ì›'),
 Document(metadata={'source': 'ë¹½ë‹¤ë°©.txt'}, page_content='6. ë¹½ì‚¬ì´ì¦ˆ ì›ì¡°ì»¤í”¼ ì œë¡œìŠˆê±°(ICED)\n  - ë¹½ë‹¤ë°©ì˜ BESTë©”ë‰´ë¥¼ ë” í¬ê²Œ, ì œë¡œìŠˆê±°ë¡œ ì¦ê²¨ë³´ì„¸ìš” :) [ì£¼ì˜. 686mg ê³ ì¹´í˜ì¸ìœ¼ë¡œ ì¹´í˜ì¸ì— ë¯¼ê°í•œ ì–´ë¦°ì´, ì„ì‚°ë¶€ëŠ” ì„­ì·¨ì— ì£¼ì˜ë°”ëë‹ˆë‹¤]\n  - ê°€ê²©: 4000ì›'),
 Document(metadata={'source': 'ë¹½ë‹¤ë°©.txt'}, page_content='7. ë¹½ì‚¬ì´ì¦ˆ ë‹¬ì½¤ì•„ì´ìŠ¤í‹°(ICED)\n  - ë¹½ë‹¤ë°©ì˜ BESTë©”ë‰´ë¥¼ ë” í¬ê²Œ ì¦ê²¨ë³´ì„¸ìš” :) ì‹œì›í•œ ë³µìˆ­ì•„ë§› ì•„ì´ìŠ¤í‹°\n  - ê°€ê²©: 4300ì›'),
 Document(metadata={'source': 'ë¹½ë‹¤ë°©.txt'}, page_content='8. ë¹½ì‚¬ì´ì¦ˆ ì•„ì´ìŠ¤í‹°ìƒ·ì¶”ê°€(ICED)\n  - SNSì—ì„œ ë” ìœ ëª…í•œ ê¿€íŒ ì¡°í•© ìŒë£Œ :) ìƒì½¤ë‹¬ì½¤í•œ ë³µìˆ­ì•„ë§› ì•„ì´ìŠ¤í‹°ì— ì§„í•œ ì—ìŠ¤í”„ë ˆì†Œ 2ìƒ·ì´ ì–´ìš°ëŸ¬ì ¸ í™˜ìƒì¡°í•©\n  - ê°€ê²©: 4800ì›'),
 Document(metadata={'source': 'ë¹½ë‹¤ë°©.txt'}, page_content='9. ë¹½ì‚¬ì´ì¦ˆ ì•„ì´ìŠ¤í‹° ë§ê³ ì¶”ê°€+ë…¸ë€ë¹¨ëŒ€\n  - SNSí•«ë©”ë‰´ ì•„ì´ìŠ¤í‹°ì— ë§ê³ ë¥¼ í•œê°€ë“:)\n  - ê°€ê²©: 6300ì›'),
 Document(metadata={'source': 'ë¹½ë‹¤ë°©.txt'}, page_content='10. ë¹½ì‚¬ì´ì¦ˆ ì´ˆì½”ë¼ë–¼(ICED)\n  - ë¹½ë‹¤ë°©ì˜ BESTë©”ë‰´ë¥¼ ë” í¬ê²Œ ì¦ê²¨ë³´ì„¸ìš” :) ì§„ì§œ~ì™„~ì „ ì§„í•œ ì´ˆì½”ë¼ë–¼\n  - ê°€ê²© : 5500ì›\n')]
```

```{admonition} ì›ë³¸ ë°ì´í„° ë³€í™˜ì´ ê°€ì¥ ì–´ë µê³  ì¤‘ìš”í•©ë‹ˆë‹¤.
:class: important

`Load` ë‹¨ê³„ì—ì„œ ì›ë³¸ ì§€ì‹ì„ ëª…í™•íˆ ì´í•´í•˜ê³  ê·¸ì— ë§ê²Œ ë³€í™˜ì„ í•´ì•¼ë§Œ, ì´í›„ `Split` ê³¼ì •ì„ ì†ì‰½ê²Œ ì§„í–‰í•  ìˆ˜ ìˆìœ¼ë©° ì •ë³´ ëˆ„ë½ì´ë‚˜ ë¬¸ë§¥ ë‹¨ì ˆë„ ìµœì†Œí™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
```

## 3ë‹¨ê³„. Embed - ê° ë¬¸ì„œë“¤ì„ ë²¡í„° ë°ì´í„°ë¡œ ë¯¸ë¦¬ ë³€í™˜í•˜ì—¬, ìœ ì‚¬ë„ ê²€ìƒ‰ ì¤€ë¹„

### ìœ ì‚¬ ë¬¸ì„œë¥¼ ì°¾ì„ë ¤ë©´?

ì»´í“¨í„°ëŠ” ë¬¸ìì—´ ê·¸ ìì²´ë¡œ ì˜ë¯¸ë¥¼ íŒŒì•…í•  ìˆ˜ëŠ” ì—†êµ¬ìš”. ì»´í“¨í„°ëŠ” ê³„ì‚°ê¸°ì´ê¸° ë•Œë¬¸ì— ë¬¸ìì—´ì„ ìˆ«ìë¡œ ë³€í™˜ì„ í•´ì•¼ í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ìˆ«ìë¥¼ ë²¡í„°(Vector)ë¼ê³  ë¶€ë¥´ë©°, ë²¡í„°ë¡œì˜ ë³€í™˜ ê³¼ì •ì„ ì„ë² ë”©(Embedding)ì´ë¼ê³  í•©ë‹ˆë‹¤.
ë²¡í„° ë³€í™˜ì€ OpenAIì˜ `text-embedding-3-small` ì„ë² ë”© ëª¨ë¸ë¡œ ë³€í™˜ì„ í–ˆêµ¬ìš”. ì´ ëª¨ë¸ì€ 1536 ì°¨ì›ì˜ ê³ ì • í¬ê¸°ì˜ ë²¡í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

+ `"ì˜¤ë Œì§€"` â†’ `[0.012021134607493877, -0.050807174295186996, ...]` (1536 ê°œì˜ ì‹¤ìˆ˜ ë°°ì—´)
+ `"ì„¤íƒ• ì»¤í”¼"` â†’ `[-0.0008126725442707539, -0.03418251499533653, ...]` (1536 ê°œì˜ ì‹¤ìˆ˜ ë°°ì—´)
+ `"ì¹´í‘¸ì¹˜ë…¸"` â†’ `[-0.02137843146920204, 0.0011899990495294333, ...]` (1536 ê°œì˜ ì‹¤ìˆ˜ ë°°ì—´)
+ `"coffee"` â†’ `[-0.01013763528317213, 0.0037400354631245136, ...]` (1536 ê°œì˜ ì‹¤ìˆ˜ ë°°ì—´)

ê° ë²¡í„° ê°’ì„ ê°€ì§€ê³ , ìœ ì‚¬ ë¬¸ì„œë¥¼ ì°¾ì•„ë‚´ëŠ” ë°©ë²•ì€ **ì½”ì‚¬ì¸ ìœ ì‚¬ë„**, ìœ í´ë¦¬ë“œ ê±°ë¦¬, ë§¨í•´íŠ¼ ê±°ë¦¬, ì ìˆ˜ ê¸°ë°˜ ìœ ì‚¬ë„, ìì¹´ë“œ ìœ ì‚¬ë„, **BM25** ë“±ì´ ìˆìŠµë‹ˆë‹¤.

ì´ ì¤‘ì— ê°€ì¥ ë§ì´ ëŒ€ì¤‘ì ì¸ ë°©ë²•ì€ **ì½”ì‚¬ì¸ ìœ ì‚¬ë„**ì´ë©° ë‘ ë²¡í„° ê°„ì˜ ê°ë„ì˜ ì½”ì‚¬ì¸ ê°’ì„ ì´ìš©í•˜ì—¬ ë²¡í„° ê°„ì˜ ìœ ì‚¬ë„ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤.
ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê°’ì˜ ë²”ìœ„ëŠ” ì½”ì‚¬ì¸ ê°’ ë²”ìœ„ì¸ `-1 â‰¤ cos(Î¸) â‰¤ 1` ì…ë‹ˆë‹¤. ê°™ì€ ë°©í–¥ì´ë©´ ê°ë„ê°€ 0ì´ë‹ˆ `cos(0) = 1` ë¡œ ê³„ì‚°ë©ë‹ˆë‹¤.

+ `1.0` â†’ ì™„ì „íˆ ë™ì¼í•œ ë²¡í„° (ë§¤ìš° ìœ ì‚¬í•¨)
+ `0.5` â†’ ì–´ëŠ ì •ë„ ê´€ë ¨ ìˆìŒ
+ `0.0` â†’ ì™„ì „íˆ ë…ë¦½ì ì¸ ì˜ë¯¸ (ì—°ê´€ ì—†ìŒ)
+ `-1.0` â†’ ì™„ì „íˆ ë°˜ëŒ€ë˜ëŠ” ë°©í–¥ (ê·¹ë‹¨ì ìœ¼ë¡œ ë‹¤ë¦„)

```{figure} ./assets/typical-cosine-similarity.png
:alt: Cosine Similarity

ì¶œì²˜ : [What is Cosine Similarity? How to Compare Text and Images in Python](https://towardsdatascience.com/what-is-cosine-similarity-how-to-compare-text-and-images-in-python-d2bb6e411ef0)
```

`"ì»¤í”¼"` ë¬¸ìì—´ê³¼ ìœ ì‚¬í•œ ë‹¨ì–´ë¥¼ ì°¾ì•„ë³¼ë ¤ê³  í•©ë‹ˆë‹¤. `"ì»¤í”¼"` ë¬¸ìì—´ì˜ ë²¡í„° ê°’ì€ `[-0.03496772050857544, -0.007349129766225815, ...]` ì´êµ¬ìš”. "ì˜¤ë Œì§€", "ì„¤íƒ• ì»¤í”¼", "ì¹´í‘¸ì¹˜ë…¸", "coffee" ë¬¸ìì—´ ê³¼ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•´ë³´ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. (`scikit-learn` ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ [`cosine_similarity`](https://scikit-learn.org/dev/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html) í•¨ìˆ˜ë¥¼ ì§€ì›í•´ì¤ë‹ˆë‹¤.)

+ ì˜ì¡´ ë¼ì´ë¸ŒëŸ¬ë¦¬ : `pip install -U scikit-learn`

```{code-block} python
:linenos:

>>> from sklearn.metrics.pairwise import cosine_similarity
>>> cosine_similarity([ì»¤í”¼_ë²¡í„°], [ì˜¤ë Œì§€_ë²¡í„°, ì„¤íƒ•_ì»¤í”¼_ë²¡í„°, ì¹´í‘¸ì¹˜ë…¸_ë²¡í„°, coffee_ë²¡í„°])
array([[0.24943755, 0.49060672, 0.24737702, 0.44323739]])
```

"ì»¤í”¼" ë¬¸ìì—´ê³¼

1. ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ìì—´ì€ "ì„¤íƒ• ì»¤í”¼" (ìœ ì‚¬ë„: 0.49060672)
2. ë‘ë²ˆì§¸ë¡œ ìœ ì‚¬í•œ ë¬¸ìì—´ì€ "coffee" (ìœ ì‚¬ë„: 0.44323739)
3. ì„¸ë²ˆì§¸ë¡œ ìœ ì‚¬í•œ ë¬¸ìì—´ì€ "ì˜¤ë Œì§€" (ìœ ì‚¬ë„: 0.24943755)
4. ë„¤ë²ˆì§¸ë¡œ ìœ ì‚¬í•œ ë¬¸ìì—´ì€ "ì¹´í‘¸ì¹˜ë…¸" (ìœ ì‚¬ë„: 0.24737702)

"ì¹´í‘¸ì¹˜ë…¸" ë³´ë‹¤ "ì˜¤ë Œì§€"ê°€ ë” ìœ ì‚¬í•˜ë‹¤ê³  ì¸¡ì •ë˜ì—ˆìŠµë‹ˆë‹¤.
"ì¹´í‘¸ì¹˜ë…¸" ëŠ” ì»¤í”¼ ì¢…ë¥˜ì´ì§€ë§Œ ë¬¸ì êµ¬ì¡° ìì²´ëŠ” "ì»¤í”¼"ì™€ ë¹„êµì  ê±°ë¦¬ê°€ ë©€ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì–´ë–¤ ì„ë² ë”© ëª¨ë¸ì„ ì‚¬ìš©í–ˆëŠ” ì§€ì™€ ì¸¡ì • ë°©ë²•ì— ë”°ë¼ ìœ ì‚¬ë„ ì¸¡ì • ê²°ê³¼ê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìœ¼ë‹ˆ, ë‹¨ìˆœíˆ ìœ ì‚¬ë„ ê°’ë§Œ ë´ì„œëŠ” ì•ˆ ë˜ê² ìŠµë‹ˆë‹¤. ğŸ˜…

### ë¬¸ì„œ ì„ë² ë”© êµ¬í˜„

ì•ì„œ ìƒì„±í–ˆë˜ ë¹½ë‹¤ë°© ë©”ë‰´ ë°ì´í„°ë¥¼ ë²¡í„° ë°ì´í„°ë¡œ ë³€í™˜í•˜ê² ìŠµë‹ˆë‹¤. `embed` í•¨ìˆ˜ì—ì„œëŠ” ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ê³ , ê° ë¬¸ì„œì˜ ë‚´ìš©(`.page_content`)ì„ ì„ë² ë”© ëª¨ë¸ì„ í†µí•´ ë²¡í„° ë°ì´í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. ê° ì›ë³¸ ë¬¸ìì—´ê³¼ ë²¡í„° ë°ì´í„°ëŠ” ë¦¬ìŠ¤íŠ¸ì— ë‹´ì•„ì„œ ë°˜í™˜í•©ë‹ˆë‹¤. ì´ë ‡ê²Œ ìƒì„±ëœ ë²¡í„° ë°ì´í„°ë¥¼ ì €ì¥í•˜ê³  ê´€ë¦¬í•˜ëŠ” ì£¼ì²´ë¥¼ `Vector Store` ë¼ê³  ë¶€ë¦…ë‹ˆë‹¤.

```{code-block} python
:linenos:

def embed(doc_list: List[Document]) -> List[Dict]:
    vector_store = []

    for doc in doc_list:
        text = doc.page_content
        response = client.embeddings.create(
            model="text-embedding-3-small",  # 1536 ì°¨ì›
            input=text,
        )
        vector_store.append(
            {
                "text": text,
                "embedding": response.data[0].embedding,
            }
        )

    return vector_store

doc_list = load()
print(f"loaded {len(doc_list)} documents")
doc_list = split(doc_list)
print(f"split into {len(doc_list)} documents")
# pprint(doc_list)

vector_store = embed(doc_list)
print(f"created {len(vector_store)} items in vector store")
for row in vector_store:
    print(
        "{}... => {} ì°¨ì›, {} ...".format(
            row["text"][:10], len(row["embedding"]), row["embedding"][:2]
        )
    )
```

ì•„ë˜ì™€ ê°™ì´ ê° ë©”ë‰´ë“¤ì´ ê°œë³„ ë¬¸ì„œë¡œ `Split`ë˜ì—ˆê³ , ê° ë¬¸ì„œê°€ 1536ì°¨ì›ì˜ ë²¡í„° ë°°ì—´ë¡œ ë³€í™˜ë˜ì—ˆìŒì„ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```{code-block} text
loaded 1 documents
split into 10 documents
created 10 items in vector store
1. ì•„ì´ìŠ¤í‹°ìƒ·ì¶”ê°€... => 1536 ì°¨ì›, [-0.02693873643875122, -0.043540798127651215] ...
2. ë°”ë‹ë¼ë¼ë–¼(I... => 1536 ì°¨ì›, [0.02490091510117054, -0.04808296635746956] ...
3. ì‚¬ë¼ë‹¤ë¹µ  ... => 1536 ì°¨ì›, [0.027449999004602432, -0.04239306598901749] ...
4. ë¹½ì‚¬ì´ì¦ˆ ì•„ë©”... => 1536 ì°¨ì›, [-0.009449880570173264, -0.03460339829325676] ...
5. ë¹½ì‚¬ì´ì¦ˆ ì›ì¡°... => 1536 ì°¨ì›, [0.03321684151887894, 0.035661567002534866] ...
6. ë¹½ì‚¬ì´ì¦ˆ ì›ì¡°... => 1536 ì°¨ì›, [0.04160701856017113, -0.0009915598202496767] ...
7. ë¹½ì‚¬ì´ì¦ˆ ë‹¬ì½¤... => 1536 ì°¨ì›, [0.014812068082392216, -0.01777448132634163] ...
8. ë¹½ì‚¬ì´ì¦ˆ ì•„ì´... => 1536 ì°¨ì›, [-0.011549889110028744, -0.02412295714020729] ...
9. ë¹½ì‚¬ì´ì¦ˆ ì•„ì´... => 1536 ì°¨ì›, [0.009231451898813248, 0.050084274262189865] ...
10. ë¹½ì‚¬ì´ì¦ˆ ì´ˆ... => 1536 ì°¨ì›, [0.0744316577911377, 0.013424741104245186] ...
```

## 4ë‹¨ê³„. Store - ë³€í™˜ëœ ë²¡í„° ë°ì´í„°ë¥¼ ë””ìŠ¤í¬ì— ì €ì¥

`list` í´ë˜ìŠ¤ë¥¼ í™•ì¥í•œ `VectorStore` í´ë˜ìŠ¤ë¥¼ êµ¬í˜„í•˜ì—¬, `VectorStore` ë‚´ì—ì„œ ë²¡í„° ë°ì´í„°ë¥¼ ì €ì¥í•˜ê³  ê´€ë¦¬í•  ìˆ˜ ìˆë„ë¡ êµ¬í˜„í•´ë³´ê² ìŠµë‹ˆë‹¤.
ë‹¤ìŒ 4ê°€ì§€ ê¸°ëŠ¥ì„ ì§€ì›í•©ë‹ˆë‹¤.

1. `make` ë©”ì„œë“œ : ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ì„œ ë²¡í„° ë°ì´í„° ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„± (`Embed` ë‹¨ê³„)
2. `save` ë©”ì„œë“œ : í˜„ì¬ì˜ ë²¡í„° ë°ì´í„° ë¦¬ìŠ¤íŠ¸ë¥¼ ë””ìŠ¤í¬ì— íŒŒì¼ë¡œ ì €ì¥
3. `load` ë©”ì„œë“œ : ë””ìŠ¤í¬ì— ì €ì¥ëœ ë²¡í„° ë°ì´í„°ë¥¼ ë¡œë”©í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ í™”
4. `search` ë©”ì„œë“œ : ì§ˆë¬¸ ë¬¸ìì—´ì„ ë°›ì•„ì„œ ìœ ì‚¬ ë¬¸ì„œ ëª©ë¡ì„ ê²€ìƒ‰

### `embed` í•¨ìˆ˜ë¥¼ `make` ë©”ì„œë“œë¡œ ë¦¬íŒ©í† ë§

ë¨¼ì € ìœ„ì—ì„œ êµ¬í˜„í•œ `embed` í•¨ìˆ˜ë¥¼ `VectorStore.make` í´ë˜ìŠ¤ í•¨ìˆ˜ë¡œ ë¦¬íŒ©í† ë§í•©ë‹ˆë‹¤.

```{code-block} python
:linenos:

class VectorStore(list):
    embedding_model = "text-embedding-3-small"

    @classmethod
    def make(cls, doc_list: List[Document]) -> "VectorStore":
        vector_store = cls()

        for doc in doc_list:
            text = doc.page_content
            response = client.embeddings.create(
                model=cls.embedding_model,
                input=text,
            )
            vector_store.append(
                {
                    "text": text,
                    "embedding": response.data[0].embedding,
                }
            )

        return vector_store

# vector_store = embed(doc_list)
vector_store = VectorStore.make(doc_list)
```

### `save` ë©”ì„œë“œì™€ `load` ë©”ì„œë“œ êµ¬í˜„

ë²¡í„° ë°ì´í„°ê°€ ë©”ëª¨ë¦¬ì—ë§Œ ì €ì¥ë˜ì–´ìˆëŠ” ìƒí™©ì´ê¸°ì— í”„ë¡œì„¸ìŠ¤ê°€ ì¢…ë£Œë˜ë©´ ë°ì´í„°ê°€ ì‚¬ë¼ì§‘ë‹ˆë‹¤. ë”°ë¼ì„œ ë°ì´í„°ë¥¼ ë””ìŠ¤í¬ì— ì €ì¥í•˜ê³  ê´€ë¦¬í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤.

ë°ì´í„°ëŠ” ë³€ê²½ë˜ì§€ ì•Šì•˜ëŠ” ë°, ë¬¸ì„œ ê²€ìƒ‰ì´ í•„ìš”í•  ë•Œë§ˆë‹¤ ë§¤ë²ˆ ëª¨ë“  ë¬¸ì„œì— ëŒ€í•´ì„œ ì„ë² ë”©ì„ ìˆ˜í–‰í•˜ê³  VectorStoreë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì€ ë¹„íš¨ìœ¨ì ì…ë‹ˆë‹¤.
ë””ìŠ¤í¬ì— íŒŒì¼ë¡œì„œ ì €ì¥í•´ì•¼ë§Œ í”„ë¡œì„¸ìŠ¤ê°€ ì¢…ë£Œë˜ì–´ë„ ë°ì´í„°ê°€ ìœ ì§€ë˜ë©°, í•„ìš”í•  ë•Œ íŒŒì¼ì„ ì½ì–´ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
íŒŒì´ì¬ ê°ì²´ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²•ìœ¼ë¡œì„œ [`pickle`ì´ íŒŒì´ì¬ ê¸°ë³¸ì—ì„œ ì§€ì›](https://docs.python.org/ko/3.13/library/pickle.html)ë©ë‹ˆë‹¤.
ë¬¼ë¡  JSONì´ë‚˜ CSV ë“± ë‹¤ì–‘í•œ í¬ë§·ìœ¼ë¡œ ì €ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```{code-block} python
:linenos:

import pickle
from pathlib import Path

class VectorStore(list):
    # ...

    def save(self, vector_store_path: Path) -> None:
        """
        í˜„ì¬ì˜ ë²¡í„° ë°ì´í„° ë¦¬ìŠ¤íŠ¸ë¥¼ ì§€ì • ê²½ë¡œì— íŒŒì¼ë¡œ ì €ì¥
        """
        with vector_store_path.open("wb") as f:
            # ë¦¬ìŠ¤íŠ¸(self)ë¥¼ pickle í¬ë§·ìœ¼ë¡œ íŒŒì¼(f)ì— ì €ì¥
            pickle.dump(self, f)

    @classmethod
    def load(cls, vector_store_path: Path) -> "VectorStore":
        """
        ì§€ì • ê²½ë¡œì— ì €ì¥ëœ íŒŒì¼ì„ ì½ì–´ì„œ ë²¡í„° ë°ì´í„° ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜
        """
        with vector_store_path.open("rb") as f:
            # pickle í¬ë§·ìœ¼ë¡œ íŒŒì¼(f)ì—ì„œ ë¦¬ìŠ¤íŠ¸(VectorStore)ë¥¼ ë¡œë”©
            return pickle.load(f)
```

### `search` ë©”ì„œë“œ êµ¬í˜„

ë‹¤ìŒ [](./typical-03) ë‹¨ê³„ì—ì„œ êµ¬í˜„í•˜ê² ìŠµë‹ˆë‹¤.

## `VectorStore` í´ë˜ìŠ¤ í˜„ì¬ ìƒí™©

```{code-block} python
:linenos:

import pickle
from pathlib import Path
from typing import List

import numpy as np
import openai
from langchain_community.utils.math import cosine_similarity
from langchain_core.documents import Document


client = openai.Client()


def load() -> List[Document]:
    file_path = "ë¹½ë‹¤ë°©.txt"
    ì§€ì‹: str = open(file_path, "rt", encoding="utf-8").read()
    docs = [
        Document(
            # ì˜ë¯¸ìˆëŠ” ë©”íƒ€ë°ì´í„°ê°€ ìˆë‹¤ë©´, ë§˜ê» ë” ë‹´ìœ¼ì‹œë©´ ë©ë‹ˆë‹¤.
            metadata={"source": file_path},
            page_content=ì§€ì‹,
        )
    ]
    return docs


def split(src_doc_list: List[Document]) -> List[Document]:
    new_doc_list = []
    for doc in src_doc_list:
        for new_page_content in doc.page_content.split("\n\n"):
            new_doc_list.append(
                Document(
                    metadata=doc.metadata.copy(),
                    page_content=new_page_content,
                )
            )
    return new_doc_list


class VectorStore(list):
    embedding_model = "text-embedding-3-small"

    @classmethod
    def make(cls, doc_list: List[Document]) -> "VectorStore":
        vector_store = cls()

        for doc in doc_list:
            text = doc.page_content
            response = client.embeddings.create(
                model=cls.embedding_model,
                input=text,
            )
            vector_store.append(
                {
                    "text": text,
                    "embedding": response.data[0].embedding,
                }
            )

        return vector_store

    def save(self, vector_store_path: Path) -> None:
        """
        í˜„ì¬ì˜ ë²¡í„° ë°ì´í„° ë¦¬ìŠ¤íŠ¸ë¥¼ ì§€ì • ê²½ë¡œì— íŒŒì¼ë¡œ ì €ì¥
        """
        with vector_store_path.open("wb") as f:
            # ë¦¬ìŠ¤íŠ¸(self)ë¥¼ pickle í¬ë§·ìœ¼ë¡œ íŒŒì¼(f)ì— ì €ì¥
            pickle.dump(self, f)

    @classmethod
    def load(cls, vector_store_path: Path) -> "VectorStore":
        """
        ì§€ì • ê²½ë¡œì— ì €ì¥ëœ íŒŒì¼ì„ ì½ì–´ì„œ ë²¡í„° ë°ì´í„° ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜
        """
        with vector_store_path.open("rb") as f:
            # pickle í¬ë§·ìœ¼ë¡œ íŒŒì¼(f)ì—ì„œ ë¦¬ìŠ¤íŠ¸(VectorStore)ë¥¼ ë¡œë”©
            return pickle.load(f)
```

ìœ„ì—ì„œ ìƒì„±ëœ `VectorStore` í´ë˜ìŠ¤ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

1. ì²«ë²ˆì§¸ ì‹¤í–‰ì—ì„œëŠ” vector_store.pickle íŒŒì¼ì´ ì—†ìœ¼ë¯€ë¡œ load, split, make, save ìˆœì„œë¡œ ë°ì´í„°ë¥¼ ìƒì„±í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.
2. ì´í›„ ì‹¤í–‰ì—ì„œëŠ” vector_store.pickle íŒŒì¼ì´ ìˆìœ¼ë¯€ë¡œ load ìˆœì„œë¡œ ë°ì´í„°ë¥¼ ë¡œë”©í•©ë‹ˆë‹¤.
3. TODO: [](./typical-03) ë‹¨ê³„ì—ì„œ ì§ˆë¬¸ì„ ë°›ê³ , RAGë¥¼ í†µí•´ ë‹µë³€ì„ êµ¬í˜„í•˜ê² ìŠµë‹ˆë‹¤.

```{code-block} python
:linenos:

def main():
    vector_store_path = Path("vector_store.pickle")

    if not vector_store_path.is_file():
        doc_list = load()
        print(f"loaded {len(doc_list)} documents")
        doc_list = split(doc_list)
        print(f"split into {len(doc_list)} documents")
        vector_store = VectorStore.make(doc_list)
        vector_store.save(vector_store_path)
        print(f"created {len(vector_store)} items in vector store")
    else:
        vector_store = VectorStore.load(vector_store_path)
        print(f"loaded {len(vector_store)} items in vector store")

    # TODO: ì§ˆë¬¸ì„ ë°›ê³ , RAGë¥¼ í†µí•´ ë‹µë³€ì„ êµ¬í˜„í•˜ê² ìŠµë‹ˆë‹¤.
    question = input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ")

if __name__ == "__main__":
    main()
```
