=========================
ğŸ“š ëª…ë ¹í–‰ RAG ì±„íŒ… êµ¬í˜„
=========================


.. admonition:: `ê´€ë ¨ ì»¤ë°‹ <https://github.com/pyhub-kr/django-webchat-rag-langcon2025/commit/06e24f8260ea3d13dea4ed6d5363783bc8846341>`_
   :class: dropdown

   * ë³€ê²½ íŒŒì¼ì„ í•œ ë²ˆì— ë®ì–´ì“°ê¸° í•˜ì‹¤ë ¤ë©´, :doc:`/utils/pyhub-git-commit-apply` ì„¤ì¹˜í•˜ì‹  í›„ì—, í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ ì•„ë˜ ëª…ë ¹ ì‹¤í–‰í•˜ì‹œë©´
     ì§€ì • ì»¤ë°‹ì˜ ëª¨ë“  íŒŒì¼ì„ ë‹¤ìš´ë°›ì•„ í˜„ì¬ ê²½ë¡œì— ë®ì–´ì“°ê¸°í•©ë‹ˆë‹¤.

   .. code-block:: bash

      python -m pyhub_git_commit_apply https://github.com/pyhub-kr/django-webchat-rag-langcon2025/commit/06e24f8260ea3d13dea4ed6d5363783bc8846341

   ``uv``\ë¥¼ ì‚¬ìš©í•˜ì‹¤ ê²½ìš° 

   .. code-block:: bash

      uv run pyhub-git-commit-apply https://github.com/pyhub-kr/django-webchat-rag-langcon2025/commit/06e24f8260ea3d13dea4ed6d5363783bc8846341


1. ì‹±ê¸€í„´ LLM ëŒ€í™”
======================

ì¥ê³  ì™¸ì ìœ¼ë¡œ íŒŒì´ì¬ ì½”ë“œ ë§Œìœ¼ë¡œ OpenAI APIë¥¼ í™œìš©í•˜ì—¬ ì‹±ê¸€í„´ LLM ëŒ€í™”ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.

ì¥ê³  í”„ë¡œì íŠ¸ ê²½ë¡œê°€ ì•„ë‹Œ ë‹¤ë¥¸ ê²½ë¡œì—ì„œë„ íŠ¹ì • ì¥ê³  í”„ë¡œì íŠ¸ ë‚´ ìì›(ëª¨ë¸, í…œí”Œë¦¿, ìºì‹œ ë“±)ë“¤ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
OpenAI API Key í™˜ê²½ë³€ìˆ˜ ê°’ ë¡œë”©ì„ ìœ„í•´ ì¥ê³  í”„ë¡œì íŠ¸ë¥¼ ë¡œë”©í•˜ì—¬ ``settings.OPENAI_API_KEY`` ê°’ì„ ì°¸ì¡°í•©ë‹ˆë‹¤.

LLM ëª¨ë¸ì€ ``gpt-4o-mini`` ëª¨ë¸ì„ ì‚¬ìš©í–ˆìœ¼ë©°, `ë‹¤ë¥¸ OpenAI API ëª¨ë¸ <https://platform.openai.com/docs/models>`_\ì„ ì‚¬ìš©í•˜ê³  ì‹¶ìœ¼ì‹œë‹¤ë©´ ì•„ë˜ ì½”ë“œì—ì„œ ``model`` ë³€ìˆ˜ ê°’ì„ ë³€ê²½í•˜ì‹œë©´ ë©ë‹ˆë‹¤.

.. admonition:: ``chat-cli.py``
    :class: dropdown

    .. code-block:: python
        :linenos:

        import os
        import django
        from openai import OpenAI

        os.environ.setdefault("DJANGO_SETTINGS_MODULE", "mysite.settings")
        django.setup()

        from django.conf import settings

        client = OpenAI(api_key=settings.OPENAI_API_KEY)


        def make_ai_message(human_message: str) -> str:
            """
            OpenAIì˜ Chat Completion APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
            """

            system_prompt = """
        ë„ˆëŠ” ë²ˆì—­ê°€ì•¼.
        í•œêµ­ì–´ë¡œ ë¬¼ì–´ë³´ë©´ í•œêµ­ì–´ë¡œ ëŒ€ë‹µí•˜ë©° ì˜ì–´ ë²ˆì—­ì„ í•¨ê»˜ ì œê³µí•´ì£¼ê³ ,
        ì˜ì–´ë¡œ ë¬¼ì–´ë³´ë©´ ì˜ì–´ë¡œ ëŒ€ë‹µí•˜ì—¬ í•œê¸€ ë²ˆì—­ì„ í•¨ê»˜ ì œê³µí•´ì¤˜.

        ì˜ˆì‹œ:

        <ì§ˆë¬¸>ì•ˆë…•í•˜ì„¸ìš”.</ì§ˆë¬¸>
        <ë‹µë³€>ë°˜ê°‘ìŠµë‹ˆë‹¤. ì €ëŠ” Tom ì…ë‹ˆë‹¤. (ì˜ì–´: Nice to meet you. I am Tom.)</ë‹µë³€>

        <ì§ˆë¬¸>Hello.</ì§ˆë¬¸>
        <ë‹µë³€>Nice to meet you. I am Tom. (í•œêµ­ì–´: ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” Tom ì…ë‹ˆë‹¤.)</ë‹µë³€>
            """

            try:
                response = client.chat.completions.create(
                    model="gpt-4o-mini",  # ë˜ëŠ” "gpt-4o" ë“± ë‹¤ë¥¸ ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥
                    messages=[
                        {
                            "role": "system",
                            "content": system_prompt,
                        },
                        {"role": "user", "content": human_message},
                    ],
                    temperature=0.2,
                    max_tokens=1000,
                )
                return response.choices[0].message.content
            except Exception as e:
                return f"API í˜¸ì¶œì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


        def main():
            human_message = input("[Human] ").strip()

            ai_message = make_ai_message(human_message)
            print(f"[AI] {ai_message}")


        if __name__ == "__main__":
            main()


í”„ë¡œì íŠ¸ ë£¨íŠ¸ ``chat-cli.py`` ê²½ë¡œì— ìœ„ ì½”ë“œë¥¼ ì €ì¥í•˜ì‹œê³  ì‹¤í–‰í•´ì£¼ì„¸ìš”.
``[Human]`` í”„ë¡¬í”„íŠ¸ë¥¼ í†µí•´ ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì‹œë©´, OpenAI LLMì„ í†µí•´ ì‘ë‹µì´ ìƒì„±ë˜ê³  ì˜ì–´/í•œê¸€ë¡œ ë²ˆì—­ëœ ë©”ì‹œì§€ë„ ê°™ì´ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

.. figure:: ./assets/rag-cli/single.png


2. ì¥ê³  ëª…ë ¹ìœ¼ë¡œ ê¸€ììˆ˜ ì‘ë‹µ ì±„íŒ… CLI êµ¬í˜„
==========================================

ì´ë²ˆì—ëŠ” ì¥ê³  ëª…ë ¹ì„ í†µí•´ ì…ë ¥ëœ í…ìŠ¤íŠ¸ì˜ ê¸€ììˆ˜ë¥¼ ë°˜í™˜í•˜ëŠ” ì±„íŒ… CLIë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.
ë³„ë„ íŒŒì´ì¬ íŒŒì¼ì´ ì•„ë‹Œ ì¥ê³  ëª…ë ¹ìœ¼ë¡œ êµ¬í˜„í•˜ë©´, ì¥ê³  í”„ë¡œì íŠ¸ ë‚´ ë‹¤ì–‘í•œ ìì›ë“¤ì„ ë³„ë„ ì„¤ì •ì—†ì´ ì‚¬ìš©í•  ìˆ˜ ìˆê³ 
ì¥ê³  ``BaseCommand``\ë¥¼ í†µí•´ ë‹¤ì–‘í•œ ëª…ë ¹ ì˜µì…˜ì„ ì†ì‰½ê²Œ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

.. admonition:: ``chat/management/commands/chat-rag-cli.py``
    :class: dropdown

    .. code-block:: python
        :linenos:

        from django.core.management.base import BaseCommand

        class Command(BaseCommand):
            help = "ì…ë ¥ëœ í…ìŠ¤íŠ¸ì˜ ê¸€ììˆ˜ë¥¼ ë°˜í™˜í•˜ëŠ” CLI ì±„íŒ…"

            def handle(self, *args, **options):
                self.stdout.write(
                    self.style.SUCCESS(
                        'í…ìŠ¤íŠ¸ ê¸€ììˆ˜ ê³„ì‚°ê¸°ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. ì¢…ë£Œí•˜ë ¤ë©´ "quit" ë˜ëŠ” "exit"ë¥¼ ì…ë ¥í•˜ì„¸ìš”.'
                    )
                )

                while True:
                    try:
                        user_input = input("\n[Human] ").strip()
                    except (KeyboardInterrupt, EOFError):
                        self.stdout.write(self.style.SUCCESS("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤."))
                        break

                    if user_input.lower() in ["quit", "exit"]:
                        self.stdout.write(self.style.SUCCESS("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤."))
                        break

                    if user_input:
                        char_count = len(user_input)
                        self.stdout.write(
                            self.style.SUCCESS(f"[AI] ì…ë ¥ëœ í…ìŠ¤íŠ¸ì˜ ê¸€ììˆ˜: {char_count}ì")
                        )

ì¥ê³  ëª…ë ¹ì€ í•­ìƒ ``ì•±/managment/commands/`` ê²½ë¡œì— ì €ì¥í•´ì•¼ë§Œ í•©ë‹ˆë‹¤. ``chat-rag-cli.py`` íŒŒì¼ë¡œ ì €ì¥í–ˆê¸° ë•Œë¬¸ì—
``python manage.py chat-rag-cli`` ëª…ë ¹ì„ í†µí•´ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

.. figure:: ./assets/rag-cli/count-ch.png


3. ë²ˆì—­ ì±„íŒ… CLI êµ¬í˜„
=========================

LLM ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ``make_ai_message`` í•¨ìˆ˜ëŠ” ì¬ì‚¬ìš©ì„±ì„ ë†’ì´ê¸° ìœ„í•´ ``chat/llm.py`` íŒŒì¼ë¡œ ë¶„ë¦¬í•˜ê³ ,
``model``, ``temperature``, ``max_tokens`` ë“± ëª¨ë¸ ì„¤ì • ì¸ìë¥¼ ì¶”ê°€í•˜ì—¬ ë” ìœ ì—°í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.

.. admonition:: ``chat/llm.py``
    :class: dropdown

    .. code-block:: python
        :linenos:

        from django.conf import settings
        from openai import OpenAI

        client = OpenAI(api_key=settings.OPENAI_API_KEY)


        def make_ai_message(
            system_prompt: str,
            human_message: str,
            model: str = "gpt-4o-mini",
            temperature: float = 0.2,
            max_tokens: int = 1000,
        ):
            """
            OpenAIì˜ Chat Completion APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
            """

            try:
                response = client.chat.completions.create(
                    model=model,
                    messages=[
                        {
                            "role": "system",
                            "content": system_prompt,
                        },
                        {"role": "user", "content": human_message},
                    ],
                    temperature=temperature,
                    max_tokens=max_tokens,
                )
                return response.choices[0].message.content
            except Exception as e:
                return f"API í˜¸ì¶œì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


``chat-rag-cli.py`` íŒŒì¼ì—ì„œëŠ” ê¸€ììˆ˜ë¥¼ ê³„ì‚°í•˜ëŠ” ``len(user_input)`` ëŒ€ì‹  ``ai_message = make_ai_message(system_prompt, user_input)`` í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ LLM ì‘ë‹µì„ ìƒì„±í•˜ê² ìŠµë‹ˆë‹¤.

.. admonition:: ``chat/management/commands/chat-rag-cli.py``
    :class: dropdown

    .. code-block:: python
        :linenos:
        :emphasize-lines: 2,40

        from django.core.management.base import BaseCommand
        from chat.llm import make_ai_message

        system_prompt = """
        ë„ˆëŠ” ë²ˆì—­ê°€ì•¼.
        í•œêµ­ì–´ë¡œ ë¬¼ì–´ë³´ë©´ í•œêµ­ì–´ë¡œ ëŒ€ë‹µí•˜ë©° ì˜ì–´ ë²ˆì—­ì„ í•¨ê»˜ ì œê³µí•´ì£¼ê³ ,
        ì˜ì–´ë¡œ ë¬¼ì–´ë³´ë©´ ì˜ì–´ë¡œ ëŒ€ë‹µí•˜ì—¬ í•œê¸€ ë²ˆì—­ì„ í•¨ê»˜ ì œê³µí•´ì¤˜.

        ì˜ˆì‹œ:

        <ì§ˆë¬¸>ì•ˆë…•í•˜ì„¸ìš”.</ì§ˆë¬¸>
        <ë‹µë³€>ë°˜ê°‘ìŠµë‹ˆë‹¤. ì €ëŠ” Tom ì…ë‹ˆë‹¤. (ì˜ì–´: Nice to meet you. I am Tom.)</ë‹µë³€>

        <ì§ˆë¬¸>Hello.</ì§ˆë¬¸>
        <ë‹µë³€>Nice to meet you. I am Tom. (í•œêµ­ì–´: ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” Tom ì…ë‹ˆë‹¤.)</ë‹µë³€>
        """

        class Command(BaseCommand):
            help = "OpenAIë¥¼ ì´ìš©í•œ ë²ˆì—­ ì±„íŒ…"

            def handle(self, *args, **options):
                self.stdout.write(
                    self.style.SUCCESS(
                        'ë²ˆì—­ ì±„íŒ…ì„ ì‹œì‘í•©ë‹ˆë‹¤. ì¢…ë£Œí•˜ë ¤ë©´ "quit" ë˜ëŠ” "exit"ë¥¼ ì…ë ¥í•˜ì„¸ìš”.'
                    )
                )

                while True:
                    try:
                        user_input = input("\n[Human] ").strip()
                    except (KeyboardInterrupt, EOFError):
                        self.stdout.write(self.style.SUCCESS("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤."))
                        break

                    if user_input.lower() in ["quit", "exit"]:
                        self.stdout.write(self.style.SUCCESS("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤."))
                        break

                    if user_input:
                        ai_message = make_ai_message(system_prompt, user_input)
                        self.stdout.write(self.style.SUCCESS(f"[AI] {ai_message}"))

``python manage.py chat-rag-cli`` ëª…ë ¹ì„ ì‹¤í–‰í•˜ë©´, ì±„íŒ…ì´ ì§„í–‰ë˜ë©° ë²ˆì—­ëœ ë©”ì‹œì§€ë¥¼ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

.. figure:: ./assets/rag-cli/translator.png

ê·¸ëŸ°ë°, ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•˜ì§€ ì•Šì•„ ëŒ€í™”ê°€ ì—°ê²°ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
ë¶„ëª… ì œê°€ ì´ë¦„ì„ ì´ì•¼ê¸°í•˜ê³  ì´ë¦„ì„ ë¬¼ì–´ë³´ëŠ” ë° ì´ë¦„ì„ ëª¨ë¥¸ë‹¤ê³  í•˜ë„¤ìš”. ğŸ˜­


4. ë©€í‹°í„´ LLM ëŒ€í™”
=====================

OpenAI LLMì„ ë¹„ë¡¯í•œ ëª¨ë“  LLMì€ ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•˜ëŠ” ê¸°ëŠ¥ì´ ì—†ìŠµë‹ˆë‹¤.
ë”°ë¼ì„œ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•˜ê³ , ë§¤ ëŒ€í™”ë§ˆë‹¤ ëŒ€í™” ê¸°ë¡ì„ ì „ë‹¬í•˜ì—¬ LLM ì‘ë‹µì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.

``make_ai_message`` í•¨ìˆ˜ë¥¼ í™•ì¥í•˜ì—¬ ``LLM`` í´ë˜ìŠ¤ë¥¼ ì •ì˜í•˜ê³ , ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•˜ëŠ” ê¸°ëŠ¥ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
``make_ai_message`` í•¨ìˆ˜ ì´ë¦„ì€ ë³´ë‹¤ ëª…í™•í•˜ê²Œ ``make_reply``\ë¡œ ë³€ê²½í–ˆìŠµë‹ˆë‹¤.

.. admonition:: ``chat/llm.py``
    :class: dropdown

    .. code-block:: python
        :linenos:
        :emphasize-lines: 8,23

        from typing import Optional, List, Dict
        from django.conf import settings
        from openai import OpenAI

        client = OpenAI(api_key=settings.OPENAI_API_KEY)


        class LLM:
            def __init__(
                self,
                model: str = "gpt-4o-mini",
                temperature: float = 0.2,
                max_tokens: int = 1000,
                system_prompt: str = "",
                initial_messages: Optional[List[Dict]] = None,
            ):
                self.model = model
                self.temperature = temperature
                self.max_tokens = max_tokens
                self.system_prompt = system_prompt
                self.history = initial_messages or []

            def make_reply(self, human_message: Optional[str] = None):
                current_messages = [
                    *self.history,
                ]

                if human_message is not None:
                    current_messages.append({"role": "user", "content": human_message})

                try:
                    response = client.chat.completions.create(
                        model=self.model,
                        messages=[
                            {
                                "role": "system",
                                "content": self.system_prompt,
                            },
                        ]
                        + current_messages,
                        temperature=self.temperature,
                        max_tokens=self.max_tokens,
                    )
                    ai_message = response.choices[0].message.content
                except Exception as e:
                    return f"API í˜¸ì¶œì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                else:
                    self.history.extend(
                        [
                            {"role": "user", "content": human_message},
                            {"role": "assistant", "content": ai_message},
                        ]
                    )
                    return ai_message


``chat-rag-cli`` ëª…ë ¹ì—ì„œëŠ” ``LLM`` í´ë˜ìŠ¤ë¥¼ í†µí•´ ëŒ€í™” ê¸°ë¡ì„ ê´€ë¦¬í•˜ê³ , ``make_reply`` í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ LLM ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.

.. admonition:: ``chat/management/commands/chat-rag-cli.py``
    :class: dropdown

    .. code-block:: python
        :linenos:
        :emphasize-lines: 2,29,43

        from django.core.management.base import BaseCommand
        from chat.llm import LLM

        system_prompt = """
        ë„ˆëŠ” ë²ˆì—­ê°€ì•¼.
        í•œêµ­ì–´ë¡œ ë¬¼ì–´ë³´ë©´ í•œêµ­ì–´ë¡œ ëŒ€ë‹µí•˜ë©° ì˜ì–´ ë²ˆì—­ì„ í•¨ê»˜ ì œê³µí•´ì£¼ê³ ,
        ì˜ì–´ë¡œ ë¬¼ì–´ë³´ë©´ ì˜ì–´ë¡œ ëŒ€ë‹µí•˜ì—¬ í•œê¸€ ë²ˆì—­ì„ í•¨ê»˜ ì œê³µí•´ì¤˜.

        ì˜ˆì‹œ:

        <ì§ˆë¬¸>ì•ˆë…•í•˜ì„¸ìš”.</ì§ˆë¬¸>
        <ë‹µë³€>ë°˜ê°‘ìŠµë‹ˆë‹¤. ì €ëŠ” Tom ì…ë‹ˆë‹¤. (ì˜ì–´: Nice to meet you. I am Tom.)</ë‹µë³€>

        <ì§ˆë¬¸>Hello.</ì§ˆë¬¸>
        <ë‹µë³€>Nice to meet you. I am Tom. (í•œêµ­ì–´: ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” Tom ì…ë‹ˆë‹¤.)</ë‹µë³€>
        """


        class Command(BaseCommand):
            help = "OpenAIë¥¼ ì´ìš©í•œ ë²ˆì—­ ì±„íŒ…"

            def handle(self, *args, **options):
                self.stdout.write(
                    self.style.SUCCESS(
                        'ë²ˆì—­ ì±„íŒ…ì„ ì‹œì‘í•©ë‹ˆë‹¤. ì¢…ë£Œí•˜ë ¤ë©´ "quit" ë˜ëŠ” "exit"ë¥¼ ì…ë ¥í•˜ì„¸ìš”.'
                    )
                )

                llm = LLM(model="gpt-4o-mini", temperature=1, system_prompt=system_prompt)

                while True:
                    try:
                        user_input = input("\n[Human] ").strip()
                    except (KeyboardInterrupt, EOFError):
                        self.stdout.write(self.style.SUCCESS("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤."))
                        break

                    if user_input.lower() in ["quit", "exit"]:
                        self.stdout.write(self.style.SUCCESS("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤."))
                        break

                    if user_input:
                        ai_message = llm.make_reply(user_input)
                        self.stdout.write(self.style.SUCCESS(f"[AI] {ai_message}"))


ì‹¤í–‰í•´ë³´ì‹œë©´, ëŒ€í™” ê¸°ë¡ì„ LLMì´ ì•Œê³  ìˆê¸°ì— ì´ë¦„ì„ ë¬¼ì–´ë³´ëŠ” ëŒ€í™”ê°€ ì´ì–´ì§ì„ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

.. figure:: ./assets/rag-cli/multi.png

íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ì¥ê³  ëª¨ë¸ì„ í†µí•´ì„œ ëŒ€í™” ê¸°ë¡ì„ ì €ì¥/ê´€ë¦¬í•˜ì‹¤ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
ì´ì— ëŒ€í•´ì„œëŠ” ë‹¤ìŒ :doc:`./chat-room` ë¬¸ì„œì—ì„œ ì´ì–´ ë‹¤ë£¨ê² ìŠµë‹ˆë‹¤.



5. RAG ëŒ€í™”
=====================

LLMì€ ê²€ìƒ‰ì—”ì§„ì´ ì•„ë‹™ë‹ˆë‹¤. ë‹¨ì§€ ì•Œê³  ìˆëŠ” ì§€ì‹ì— ê¸°ë°˜í•´ì„œ ë‹µë³€ì„ ìƒì„±í•  ë¿ì…ë‹ˆë‹¤.
ë”°ë¼ì„œ LLMì´ ëª¨ë¥´ëŠ” ì§€ì‹ì— ëŒ€í•´ì„œëŠ” í™˜ê° (Hallucination)ì´ ë°œìƒí•  ìˆ˜ ë°–ì— ì—†ìŠµë‹ˆë‹¤.
ì¶©ë¶„í•œ ì§€ì‹ì´ ìˆëŠ” ìƒí™©ì—ì„œëŠ” í™˜ê°ì´ ë°œìƒí•  í™•ë¥ ì´ ë‚®ì•„ì§‘ë‹ˆë‹¤.

.. tip::

    RAG ê°œë…ì— ëŒ€í•´ì„œëŠ” :doc:`/rag-01/index` íŠœí† ë¦¬ì–¼ê³¼ :doc:`/rag-02/index` íŠœí† ë¦¬ì–¼ì„ ì°¸ê³ í•˜ì„¸ìš”.

.. figure:: /rag-01/assets/llm-rag.png
   :name: llm-rag

   ê´€ë ¨ ì§€ì‹ê³¼ í•¨ê»˜ ì§ˆë¬¸í•˜ë©´, LLMì´ ëª¨ë¥´ëŠ” ì§€ì‹(ë²•ë ¹, íšŒì‚¬ ì •ë³´ ë“±)ì„ ë³´ì¶©í•´ì„œ ì •í™•í•œ ë‹µë³€ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

RAGëŠ” LLMì—ê²Œ ë‹µë³€ì„ ìš”ì²­í•˜ê¸° ì „ì—, ë¯¸ë¦¬ **ì§ˆë¬¸ê³¼ ë¹„ìŠ·í•œ ë‚´ìš©ì˜  ì§€ì‹**\ì„ ê²€ìƒ‰í•˜ì—¬ ì°¾ì€ ì§€ì‹ê³¼ ì§ˆë¬¸ì„ LLMì—ê²Œ í•¨ê»˜ ì œê³µí•˜ì—¬,
ì •í™•í•œ ì§€ì‹ì— ê¸°ë°˜í•˜ì—¬ LLMì´ ë‚´ìš©ì„ ì •ë¦¬í•´ì£¼ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.
ì´ëŸ¬í•œ ì§€ì‹ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ Vector Storeë¼ê³  ë¶€ë¦…ë‹ˆë‹¤. ë‹¤ì–‘í•œ Vector Store ì†”ë£¨ì…˜ì´ ìˆì§€ë§Œ,
ìš°ë¦¬ëŠ” ì¥ê³  ëª¨ë¸ì„ í†µí•´ Vector Storeë¥¼ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤.

sqlite-vec/pgvector ê¸°ë°˜ìœ¼ë¡œ ì¥ê³  ëª¨ë¸ì„ í†µí•´ ë²¡í„° ìŠ¤í† ì–´ë¥¼ êµ¬í˜„í•˜ë©´, ë‹¤ìŒê³¼ ê°™ì€ ì¥ì ì´ ìˆìŠµë‹ˆë‹¤:

1. ì• í”Œë¦¬ì¼€ì´ì…˜ í†µí•©ì„± - ë³„ë„ ì¸í”„ë¼ ì¶”ê°€ì—†ì´ ë¹ ë¥´ê²Œ ë²¡í„° ìŠ¤í† ì–´ë¥¼ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë¬¼ë¡  **ë¬¸ì„œë§Œ ë³„ë„ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ í†µí•´ ê´€ë¦¬í•  ìˆ˜ë„** ìˆìŠµë‹ˆë‹¤.
2. í™•ì¥ì„± - ìƒí™©ì— ë”°ë¼ (ë¡œì»¬í™˜ê²½, ì†Œê·œëª¨, ëŒ€ê·œëª¨ ìš´ì˜í™˜ê²½) SQLite, PostgreSQL ë“± ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—”ë“œë¥¼ ë³€ê²½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
3. ê´€ë¦¬ ìš©ì´ì„± - ì¥ê³  ì–´ë“œë¯¼ì„ í†µí•´ ë²¡í„° ë°ì´í„°ë¥¼ ì‰½ê²Œ ê´€ë¦¬í•˜ê³  ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
4. ì¼ê´€ëœ ë°ì´í„° ì ‘ê·¼ - ë‹¤ë¥¸ ëª¨ë¸ê³¼ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ë²¡í„° ë°ì´í„°ì— ì ‘ê·¼í•  ìˆ˜ ìˆì–´ ê°œë°œ ì¼ê´€ì„±ì´ ìœ ì§€ë©ë‹ˆë‹¤.
5. ë§ˆì´ê·¸ë ˆì´ì…˜ ì§€ì› - ì¥ê³ ì˜ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œìŠ¤í…œì„ í†µí•´ ë²¡í„° ìŠ¤í† ì–´ ìŠ¤í‚¤ë§ˆ ë³€ê²½ì„ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ë‹¤ìŒê³¼ ê°™ì´ ê°„ê²°í•˜ê²Œ ì§€ì‹ì„ ì°¾ê³  í”„ë¡¬í”„íŠ¸ì— ì ìš©í•˜ì—¬ RAG ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

.. code-block:: python

    user_input = "ì¬í™” ìˆ˜ì¶œí•˜ëŠ” ê²½ìš° ì˜ì„¸ìœ¨ ì²¨ë¶€ ì„œë¥˜ë¡œ ìˆ˜ì¶œì‹¤ì ëª…ì„¸ì„œê°€ ì—†ëŠ” ê²½ìš° í•´ê²° ë°©ë²•"

    doc_list = TaxLawDocument.objects.similarity_search(user_input)
    ì§€ì‹ = str(doc_list)
    user_input = f"""<context>{ì§€ì‹}</context>\n\nì§ˆë¬¸ : {user_input}"""


.. admonition:: ``chat/management/commands/chat-rag-cli.py``
    :class: dropdown

    .. code-block:: python
        :linenos:
        :emphasize-lines: 3,6-30,38,54-60

        from django.core.management.base import BaseCommand
        from chat.llm import LLM
        from chat.models import TaxLawDocument

        system_prompt = """
        ëŒ€í•œë¯¼êµ­ ì„¸ë¬´/íšŒê³„ ì •ë³´ ì±—ë´‡ìœ¼ë¡œì„œ, ì£¼ì–´ì§„ ì§ˆë‹µ ì§€ì‹ì—ì„œ ì‚¬ì‹¤ê³¼ ì˜ê²¬ì„ êµ¬ë³„í•˜ì—¬ ì‚¬ì‹¤ ì •ë³´ë§Œì„ ì •ë¦¬í•˜ê³ ,
        ê° ë‹µë³€ì— í•´ë‹¹ ì •ë³´ì˜ ì¶œì²˜ê¹Œì§€ í•¨ê»˜ ê¸°ì…í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.

        # Steps

        1. ì´í•´í•˜ê¸°: ì§ˆë¬¸ê³¼ ì œê³µëœ ì§€ì‹ì„ ì£¼ì˜ ê¹Šê²Œ ì½ê³  ì •í™•íˆ ì´í•´í•©ë‹ˆë‹¤.
        2. ì •ë³´ êµ¬ë¶„í•˜ê¸°: ì§ˆë‹µ ì§€ì‹ì—ì„œ ì‚¬ì‹¤ê³¼ ì˜ê²¬ì„ ì‹ë³„í•©ë‹ˆë‹¤.
        - ì‚¬ì‹¤: ê²€ì¦ ê°€ëŠ¥í•œ ë°ì´í„°, ë²•ë¥ , ê·œì • ë° ìˆ˜ì¹˜ ë“±
        - ì˜ê²¬: ê°œì¸ì˜ ê²¬í•´, í•´ì„, ì¶”ì²œ ë“±
        3. ì‚¬ì‹¤ ì •ë¦¬í•˜ê¸°: ì‹ë³„ëœ ì‚¬ì‹¤ ì •ë³´ë¥¼ ë…¼ë¦¬ì ì´ê³  ëª…í™•í•˜ê²Œ ì •ë¦¬í•˜ë©°, ë¶ˆí•„ìš”í•œ ë¶€ë¶„ì€ ì œê±°í•©ë‹ˆë‹¤.
        4. ë‹µë³€ ì‘ì„±í•˜ê¸°: ì •ë¦¬ëœ ì‚¬ì‹¤ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ëª…ë£Œí•˜ê³  ê°„ê²°í•œ ë¬¸ì¥ìœ¼ë¡œ êµ¬ì„±ëœ ë‹¨ë½ í˜•íƒœì˜ ë‹µë³€ì„ ì‘ì„±í•©ë‹ˆë‹¤. ë°˜ë“œì‹œ í•´ë‹¹ ì‚¬ì‹¤ ì •ë³´ì˜ ì¶œì²˜ë¥¼ í•¨ê»˜ ëª…ì‹œí•©ë‹ˆë‹¤.
        - ê°€ëŠ¥í•œ ê²½ìš° ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¶œì²˜(ì˜ˆ: ì •ë¶€ ê¸°ê´€, ê³µì‹ ë¬¸ì„œ, í•™ìˆ ìë£Œ ë“±)ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.
        - ì¶œì²˜ê°€ í™•ì¸ë˜ì§€ ì•Šê±°ë‚˜ ì—†ëŠ” ê²½ìš°, â€œì¶œì²˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤â€ë¼ê³  ëª…ì‹œí•©ë‹ˆë‹¤.
        - ì¶œì²˜ì— ë¬¸ì„œIDê°€ í¬í•¨ëœ ê²½ìš°, ë°˜ë“œì‹œ ë¬¸ì„œIDë¥¼ ê¸°ì…í•˜ê³  ì•„ë˜ URL í˜•ì‹ì„ ì°¸ê³ í•˜ì—¬ í•´ë‹¹ URLë„ í•¨ê»˜ í¬í•¨í•©ë‹ˆë‹¤.

        # Output Format

        - ëª…ë£Œí•˜ê³  ê°„ê²°í•œ ë¬¸ì¥ìœ¼ë¡œ êµ¬ì„±ëœ ë‹¨ë½ í˜•íƒœì˜ ë‹µë³€
        - ë‹µë³€ ë‚´ì— ì‚¬ìš©í•œ ì •ë³´ì˜ ì¶œì²˜ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•˜ì—¬ ì‘ì„±

        # Notes

        - ê° ì„¸ë¬´/íšŒê³„ ì •ë³´ë¥¼ ê°ê´€ì ìœ¼ë¡œ í‰ê°€í•˜ì—¬ ë‹µë³€ì„ ì‘ì„±í•©ë‹ˆë‹¤.
        - ëª¨í˜¸í•˜ê±°ë‚˜ ë¶ˆí™•ì‹¤í•œ ì •ë³´ëŠ” ì œì™¸í•©ë‹ˆë‹¤.
        - ë‹µë³€ì— ë°˜ë“œì‹œ ê´€ë ¨ ì‚¬ì‹¤ ì •ë³´ì˜ ì¶œì²˜ë¥¼ í•¨ê»˜ ê¸°ì…í•˜ì—¬ ê°ê´€ì„±ê³¼ ì‹ ë¢°ì„±ì„ ë†’ì…ë‹ˆë‹¤.
        """


        class Command(BaseCommand):
            help = "OpenAIë¥¼ ì´ìš©í•œ ë²ˆì—­ ì±„íŒ…"

            def handle(self, *args, **options):
                self.stdout.write(self.style.SUCCESS('ì„¸ë¬´/íšŒê³„ ì •ë³´ ì±—ë´‡ì„ ì‹œì‘í•©ë‹ˆë‹¤. ì¢…ë£Œí•˜ë ¤ë©´ "quit" ë˜ëŠ” "exit"ë¥¼ ì…ë ¥í•˜ì„¸ìš”.'))

                llm = LLM(model="gpt-4o-mini", temperature=1, system_prompt=system_prompt)

                while True:
                    try:
                        user_input = input("\n[Human] ").strip()
                    except (KeyboardInterrupt, EOFError):
                        self.stdout.write(self.style.SUCCESS("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤."))
                        break

                    if user_input.lower() in ["quit", "exit"]:
                        self.stdout.write(self.style.SUCCESS("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤."))
                        break

                    if user_input:
                        # ì„¸ë²• í•´ì„ë¡€ ë¬¸ì„œ ê²€ìƒ‰ì´ í•„ìš”í•  ë•Œ
                        if user_input.startswith("!"):
                            user_input = user_input[1:].strip()
                            # RAGë¥¼ ì›í•˜ëŠ” ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰
                            doc_list = TaxLawDocument.objects.similarity_search(user_input)
                            ì§€ì‹ = str(doc_list)
                            user_input = f"""<context>{ì§€ì‹}</context>\n\nì§ˆë¬¸ : {user_input}"""

                        ai_message = llm.make_reply(user_input)
                        self.stdout.write(self.style.SUCCESS(f"[AI] {ai_message}"))


.. figure:: ./assets/rag-cli/rag.png
