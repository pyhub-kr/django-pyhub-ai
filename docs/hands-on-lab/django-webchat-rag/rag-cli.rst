=========================
ğŸ“š ëª…ë ¹í–‰ RAG ì±„íŒ… êµ¬í˜„
=========================

1. ì‹±ê¸€í„´ LLM ëŒ€í™”
======================

ì¥ê³  ì™¸ì ìœ¼ë¡œ íŒŒì´ì¬ ì½”ë“œ ë§Œìœ¼ë¡œ OpenAI APIë¥¼ í™œìš©í•˜ì—¬ ì‹±ê¸€í„´ LLM ëŒ€í™”ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.

ì¥ê³  í”„ë¡œì íŠ¸ ê²½ë¡œê°€ ì•„ë‹Œ ë‹¤ë¥¸ ê²½ë¡œì—ì„œë„ íŠ¹ì • ì¥ê³  í”„ë¡œì íŠ¸ ë‚´ ìì›(ëª¨ë¸, í…œí”Œë¦¿, ìºì‹œ ë“±)ë“¤ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
OpenAI API Key í™˜ê²½ë³€ìˆ˜ ê°’ ë¡œë”©ì„ ìœ„í•´ ì¥ê³  í”„ë¡œì íŠ¸ë¥¼ ë¡œë”©í•˜ì—¬ ``settings.OPENAI_API_KEY`` ê°’ì„ ì°¸ì¡°í•©ë‹ˆë‹¤.

LLM ëª¨ë¸ì€ ``gpt-4o-mini`` ëª¨ë¸ì„ ì‚¬ìš©í–ˆìœ¼ë©°, `ë‹¤ë¥¸ OpenAI API ëª¨ë¸ <https://platform.openai.com/docs/models>`_\ì„ ì‚¬ìš©í•˜ê³  ì‹¶ìœ¼ì‹œë‹¤ë©´ ì•„ë˜ ì½”ë“œì—ì„œ ``model`` ë³€ìˆ˜ ê°’ì„ ë³€ê²½í•˜ì‹œë©´ ë©ë‹ˆë‹¤.

.. admonition:: ``chat-cli.py``
    :class: dropdown

    .. code-block:: python
        :linenos:

        import os
        import django
        from openai import OpenAI

        os.environ.setdefault("DJANGO_SETTINGS_MODULE", "mysite.settings")
        django.setup()

        from django.conf import settings

        client = OpenAI(api_key=settings.OPENAI_API_KEY)

        def make_ai_message(human_message: str) -> str:
            """
            OpenAIì˜ Chat Completion APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
            """

            system_prompt = """
        ë„ˆëŠ” ë²ˆì—­ê°€ì•¼.
        í•œêµ­ì–´ë¡œ ë¬¼ì–´ë³´ë©´ í•œêµ­ì–´ë¡œ ëŒ€ë‹µí•˜ë©° ì˜ì–´ ë²ˆì—­ì„ í•¨ê»˜ ì œê³µí•´ì£¼ê³ ,
        ì˜ì–´ë¡œ ë¬¼ì–´ë³´ë©´ ì˜ì–´ë¡œ ëŒ€ë‹µí•˜ì—¬ í•œê¸€ ë²ˆì—­ì„ í•¨ê»˜ ì œê³µí•´ì¤˜.

        ì˜ˆì‹œ:

        <ì§ˆë¬¸>ì•ˆë…•í•˜ì„¸ìš”.</ì§ˆë¬¸>
        <ë‹µë³€>ë°˜ê°‘ìŠµë‹ˆë‹¤. ì €ëŠ” Tom ì…ë‹ˆë‹¤. (ì˜ì–´: Nice to meet you. I am Tom.)</ë‹µë³€>

        <ì§ˆë¬¸>Hello.</ì§ˆë¬¸>
        <ë‹µë³€>Nice to meet you. I am Tom. (í•œêµ­ì–´: ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” Tom ì…ë‹ˆë‹¤.)</ë‹µë³€>
            """

            try:
                response = client.chat.completions.create(
                    model="gpt-4o-mini",  # ë˜ëŠ” "gpt-4o" ë“± ë‹¤ë¥¸ ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥
                    messages=[
                        {
                            "role": "system",
                            "content": system_prompt,
                        },
                        {"role": "user", "content": human_message},
                    ],
                    temperature=0.2,
                    max_tokens=1000,
                )
                return response.choices[0].message.content
            except Exception as e:
                return f"API í˜¸ì¶œì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


        if __name__ == "__main__":

            human_message = input("[Human] ").strip()

            ai_message = make_ai_message(human_message)
            print(f"[AI] {ai_message}")

í”„ë¡œì íŠ¸ ë£¨íŠ¸ ``chat-cli.py`` ê²½ë¡œì— ìœ„ ì½”ë“œë¥¼ ì €ì¥í•˜ì‹œê³  ì‹¤í–‰í•´ì£¼ì„¸ìš”.
``[Human]`` í”„ë¡¬í”„íŠ¸ë¥¼ í†µí•´ ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì‹œë©´, OpenAI LLMì„ í†µí•´ ì‘ë‹µì´ ìƒì„±ë˜ê³  ì˜ì–´/í•œê¸€ë¡œ ë²ˆì—­ëœ ë©”ì‹œì§€ë„ ê°™ì´ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

.. figure:: ./assets/rag-cli/single.png


2. ì¥ê³  ëª…ë ¹ìœ¼ë¡œ ê¸€ììˆ˜ ì‘ë‹µ ì±„íŒ… CLI êµ¬í˜„
==========================================

ì´ë²ˆì—ëŠ” ì¥ê³  ëª…ë ¹ì„ í†µí•´ ì…ë ¥ëœ í…ìŠ¤íŠ¸ì˜ ê¸€ììˆ˜ë¥¼ ë°˜í™˜í•˜ëŠ” ì±„íŒ… CLIë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.
ë³„ë„ íŒŒì´ì¬ íŒŒì¼ì´ ì•„ë‹Œ ì¥ê³  ëª…ë ¹ìœ¼ë¡œ êµ¬í˜„í•˜ë©´, ì¥ê³  í”„ë¡œì íŠ¸ ë‚´ ë‹¤ì–‘í•œ ìì›ë“¤ì„ ë³„ë„ ì„¤ì •ì—†ì´ ì‚¬ìš©í•  ìˆ˜ ìˆê³ 
ì¥ê³  ``BaseCommand``\ë¥¼ í†µí•´ ë‹¤ì–‘í•œ ëª…ë ¹ ì˜µì…˜ì„ ì†ì‰½ê²Œ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

.. admonition:: ``chat/management/commands/chat-rag-cli.py``
    :class: dropdown

    .. code-block:: python
        :linenos:

        from django.core.management.base import BaseCommand

        class Command(BaseCommand):
            help = "ì…ë ¥ëœ í…ìŠ¤íŠ¸ì˜ ê¸€ììˆ˜ë¥¼ ë°˜í™˜í•˜ëŠ” CLI ì±„íŒ…"

            def handle(self, *args, **options):
                self.stdout.write(
                    self.style.SUCCESS(
                        'í…ìŠ¤íŠ¸ ê¸€ììˆ˜ ê³„ì‚°ê¸°ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. ì¢…ë£Œí•˜ë ¤ë©´ "quit" ë˜ëŠ” "exit"ë¥¼ ì…ë ¥í•˜ì„¸ìš”.'
                    )
                )

                while True:
                    try:
                        user_input = input("\n[Human] ").strip()
                    except (KeyboardInterrupt, EOFError):
                        self.stdout.write(self.style.SUCCESS("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤."))
                        break

                    if user_input.lower() in ["quit", "exit"]:
                        self.stdout.write(self.style.SUCCESS("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤."))
                        break

                    if user_input:
                        char_count = len(user_input)
                        self.stdout.write(
                            self.style.SUCCESS(f"[AI] ì…ë ¥ëœ í…ìŠ¤íŠ¸ì˜ ê¸€ììˆ˜: {char_count}ì")
                        )

ì¥ê³  ëª…ë ¹ì€ í•­ìƒ ``ì•±/managment/commands/`` ê²½ë¡œì— ì €ì¥í•´ì•¼ë§Œ í•©ë‹ˆë‹¤. ``chat-rag-cli.py`` íŒŒì¼ë¡œ ì €ì¥í–ˆê¸° ë•Œë¬¸ì—
``python manage.py chat-rag-cli`` ëª…ë ¹ì„ í†µí•´ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

.. figure:: ./assets/rag-cli/count-ch.png


3. ë²ˆì—­ ì±„íŒ… CLI êµ¬í˜„
=========================

LLM ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ``make_ai_message`` í•¨ìˆ˜ëŠ” ì¬ì‚¬ìš©ì„±ì„ ë†’ì´ê¸° ìœ„í•´ ``chat/llm.py`` íŒŒì¼ë¡œ ë¶„ë¦¬í•˜ê³ ,
``model``, ``temperature``, ``max_tokens`` ë“± ëª¨ë¸ ì„¤ì • ì¸ìë¥¼ ì¶”ê°€í•˜ì—¬ ë” ìœ ì—°í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.

.. admonition:: ``chat/llm.py``
    :class: dropdown

    .. code-block:: python
        :linenos:

        from django.conf import settings
        from openai import OpenAI

        client = OpenAI(api_key=settings.OPENAI_API_KEY)


        def make_ai_message(
            system_prompt: str,
            human_message: str,
            model: str = "gpt-4o-mini",
            temperature: float = 0.2,
            max_tokens: int = 1000,
        ):
            """
            OpenAIì˜ Chat Completion APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
            """

            try:
                response = client.chat.completions.create(
                    model=model,
                    messages=[
                        {
                            "role": "system",
                            "content": system_prompt,
                        },
                        {"role": "user", "content": human_message},
                    ],
                    temperature=temperature,
                    max_tokens=max_tokens,
                )
                return response.choices[0].message.content
            except Exception as e:
                return f"API í˜¸ì¶œì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


``chat-rag-cli.py`` íŒŒì¼ì—ì„œëŠ” ê¸€ììˆ˜ë¥¼ ê³„ì‚°í•˜ëŠ” ``len(user_input)`` ëŒ€ì‹  ``ai_message = make_ai_message(system_prompt, user_input)`` í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ LLM ì‘ë‹µì„ ìƒì„±í•˜ê² ìŠµë‹ˆë‹¤.

.. admonition:: ``chat/management/commands/chat-rag-cli.py``
    :class: dropdown

    .. code-block:: python
        :linenos:
        :emphasize-lines: 2,40

        from django.core.management.base import BaseCommand
        from chat.llm import make_ai_message

        system_prompt = """
        ë„ˆëŠ” ë²ˆì—­ê°€ì•¼.
        í•œêµ­ì–´ë¡œ ë¬¼ì–´ë³´ë©´ í•œêµ­ì–´ë¡œ ëŒ€ë‹µí•˜ë©° ì˜ì–´ ë²ˆì—­ì„ í•¨ê»˜ ì œê³µí•´ì£¼ê³ ,
        ì˜ì–´ë¡œ ë¬¼ì–´ë³´ë©´ ì˜ì–´ë¡œ ëŒ€ë‹µí•˜ì—¬ í•œê¸€ ë²ˆì—­ì„ í•¨ê»˜ ì œê³µí•´ì¤˜.

        ì˜ˆì‹œ:

        <ì§ˆë¬¸>ì•ˆë…•í•˜ì„¸ìš”.</ì§ˆë¬¸>
        <ë‹µë³€>ë°˜ê°‘ìŠµë‹ˆë‹¤. ì €ëŠ” Tom ì…ë‹ˆë‹¤. (ì˜ì–´: Nice to meet you. I am Tom.)</ë‹µë³€>

        <ì§ˆë¬¸>Hello.</ì§ˆë¬¸>
        <ë‹µë³€>Nice to meet you. I am Tom. (í•œêµ­ì–´: ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” Tom ì…ë‹ˆë‹¤.)</ë‹µë³€>
        """

        class Command(BaseCommand):
            help = "OpenAIë¥¼ ì´ìš©í•œ ë²ˆì—­ ì±„íŒ…"

            def handle(self, *args, **options):
                self.stdout.write(
                    self.style.SUCCESS(
                        'ë²ˆì—­ ì±„íŒ…ì„ ì‹œì‘í•©ë‹ˆë‹¤. ì¢…ë£Œí•˜ë ¤ë©´ "quit" ë˜ëŠ” "exit"ë¥¼ ì…ë ¥í•˜ì„¸ìš”.'
                    )
                )

                while True:
                    try:
                        user_input = input("\n[Human] ").strip()
                    except (KeyboardInterrupt, EOFError):
                        self.stdout.write(self.style.SUCCESS("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤."))
                        break

                    if user_input.lower() in ["quit", "exit"]:
                        self.stdout.write(self.style.SUCCESS("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤."))
                        break

                    if user_input:
                        ai_message = make_ai_message(system_prompt, user_input)
                        self.stdout.write(self.style.SUCCESS(f"[AI] {ai_message}"))

``python manage.py chat-rag-cli`` ëª…ë ¹ì„ ì‹¤í–‰í•˜ë©´, ì±„íŒ…ì´ ì§„í–‰ë˜ë©° ë²ˆì—­ëœ ë©”ì‹œì§€ë¥¼ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

.. figure:: ./assets/rag-cli/translator.png

ê·¸ëŸ°ë°, ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•˜ì§€ ì•Šì•„ ëŒ€í™”ê°€ ì—°ê²°ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
ë¶„ëª… ì œê°€ ì´ë¦„ì„ ì´ì•¼ê¸°í•˜ê³  ì´ë¦„ì„ ë¬¼ì–´ë³´ëŠ” ë° ì´ë¦„ì„ ëª¨ë¥¸ë‹¤ê³  í•˜ë„¤ìš”. ğŸ˜­


4. ë©€í‹°í„´ LLM ëŒ€í™”
=====================

OpenAI LLMì„ ë¹„ë¡¯í•œ ëª¨ë“  LLMì€ ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•˜ëŠ” ê¸°ëŠ¥ì´ ì—†ìŠµë‹ˆë‹¤.
ë”°ë¼ì„œ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•˜ê³ , ë§¤ ëŒ€í™”ë§ˆë‹¤ ëŒ€í™” ê¸°ë¡ì„ ì „ë‹¬í•˜ì—¬ LLM ì‘ë‹µì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.

``make_ai_message`` í•¨ìˆ˜ë¥¼ í™•ì¥í•˜ì—¬ ``LLM`` í´ë˜ìŠ¤ë¥¼ ì •ì˜í•˜ê³ , ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•˜ëŠ” ê¸°ëŠ¥ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
``make_ai_message`` í•¨ìˆ˜ ì´ë¦„ì€ ë³´ë‹¤ ëª…í™•í•˜ê²Œ ``make_reply``\ë¡œ ë³€ê²½í–ˆìŠµë‹ˆë‹¤.

.. admonition:: ``chat/llm.py``
    :class: dropdown

    .. code-block:: python
        :linenos:
        :emphasize-lines: 8,23

        from typing import Optional, List, Dict
        from django.conf import settings
        from openai import OpenAI

        client = OpenAI(api_key=settings.OPENAI_API_KEY)


        class LLM:
            def __init__(
                self,
                model: str = "gpt-4o-mini",
                temperature: float = 0.2,
                max_tokens: int = 1000,
                system_prompt: str = "",
                initial_messages: Optional[List[Dict]] = None,
            ):
                self.model = model
                self.temperature = temperature
                self.max_tokens = max_tokens
                self.system_prompt = system_prompt
                self.history = initial_messages or []

            def make_reply(self, human_message: Optional[str] = None):
                current_messages = [
                    *self.history,
                ]

                if human_message is not None:
                    current_messages.append({"role": "user", "content": human_message})

                try:
                    response = client.chat.completions.create(
                        model=self.model,
                        messages=[
                            {
                                "role": "system",
                                "content": self.system_prompt,
                            },
                        ]
                        + current_messages,
                        temperature=self.temperature,
                        max_tokens=self.max_tokens,
                    )
                    ai_message = response.choices[0].message.content
                except Exception as e:
                    return f"API í˜¸ì¶œì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                else:
                    self.history.extend(
                        [
                            {"role": "user", "content": human_message},
                            {"role": "assistant", "content": ai_message},
                        ]
                    )
                    return ai_message


``chat-rag-cli`` ëª…ë ¹ì—ì„œëŠ” ``LLM`` í´ë˜ìŠ¤ë¥¼ í†µí•´ ëŒ€í™” ê¸°ë¡ì„ ê´€ë¦¬í•˜ê³ , ``make_reply`` í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ LLM ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.

.. admonition:: ``chat/management/commands/chat-rag-cli.py``
    :class: dropdown

    .. code-block:: python
        :linenos:
        :emphasize-lines: 2,29,43

        from django.core.management.base import BaseCommand
        from chat.llm import LLM

        system_prompt = """
        ë„ˆëŠ” ë²ˆì—­ê°€ì•¼.
        í•œêµ­ì–´ë¡œ ë¬¼ì–´ë³´ë©´ í•œêµ­ì–´ë¡œ ëŒ€ë‹µí•˜ë©° ì˜ì–´ ë²ˆì—­ì„ í•¨ê»˜ ì œê³µí•´ì£¼ê³ ,
        ì˜ì–´ë¡œ ë¬¼ì–´ë³´ë©´ ì˜ì–´ë¡œ ëŒ€ë‹µí•˜ì—¬ í•œê¸€ ë²ˆì—­ì„ í•¨ê»˜ ì œê³µí•´ì¤˜.

        ì˜ˆì‹œ:

        <ì§ˆë¬¸>ì•ˆë…•í•˜ì„¸ìš”.</ì§ˆë¬¸>
        <ë‹µë³€>ë°˜ê°‘ìŠµë‹ˆë‹¤. ì €ëŠ” Tom ì…ë‹ˆë‹¤. (ì˜ì–´: Nice to meet you. I am Tom.)</ë‹µë³€>

        <ì§ˆë¬¸>Hello.</ì§ˆë¬¸>
        <ë‹µë³€>Nice to meet you. I am Tom. (í•œêµ­ì–´: ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” Tom ì…ë‹ˆë‹¤.)</ë‹µë³€>
        """


        class Command(BaseCommand):
            help = "OpenAIë¥¼ ì´ìš©í•œ ë²ˆì—­ ì±„íŒ…"

            def handle(self, *args, **options):
                self.stdout.write(
                    self.style.SUCCESS(
                        'ë²ˆì—­ ì±„íŒ…ì„ ì‹œì‘í•©ë‹ˆë‹¤. ì¢…ë£Œí•˜ë ¤ë©´ "quit" ë˜ëŠ” "exit"ë¥¼ ì…ë ¥í•˜ì„¸ìš”.'
                    )
                )

                llm = LLM(model="gpt-4o-mini", temperature=1, system_prompt=system_prompt)

                while True:
                    try:
                        user_input = input("\n[Human] ").strip()
                    except (KeyboardInterrupt, EOFError):
                        self.stdout.write(self.style.SUCCESS("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤."))
                        break

                    if user_input.lower() in ["quit", "exit"]:
                        self.stdout.write(self.style.SUCCESS("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤."))
                        break

                    if user_input:
                        ai_message = llm.make_reply(user_input)
                        self.stdout.write(self.style.SUCCESS(f"[AI] {ai_message}"))


ì‹¤í–‰í•´ë³´ì‹œë©´, ëŒ€í™” ê¸°ë¡ì„ LLMì´ ì•Œê³  ìˆê¸°ì— ì´ë¦„ì„ ë¬¼ì–´ë³´ëŠ” ëŒ€í™”ê°€ ì´ì–´ì§ì„ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

.. figure:: ./assets/rag-cli/multi.png

íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ì¥ê³  ëª¨ë¸ì„ í†µí•´ì„œ ëŒ€í™” ê¸°ë¡ì„ ì €ì¥/ê´€ë¦¬í•˜ì‹¤ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
ì´ì— ëŒ€í•´ì„œëŠ” ë‹¤ìŒ :doc:`./chat-room` ë¬¸ì„œì—ì„œ ì´ì–´ ë‹¤ë£¨ê² ìŠµë‹ˆë‹¤.
